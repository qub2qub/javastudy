05 Building Blocks

почему нельзя сделать синхронизированный конструктор?
http://docs.oracle.com/javase/specs/jls/se8/html/jls-8.html#jls-8.8.3
http://stackoverflow.com/questions/4880168/why-cant-java-constructors-be-synchronized

Java theory and practice: Safe construction techniques
http://www.ibm.com/developerworks/java/library/j-jtp0618/index.html

можно ли добавить синхронизацию в интерфейс?
НЕТ.

Where practical, delegation is one of the most effective strategies for creating thread-safe classes: just let existing thread-safe classes manage all the state.

****synchronized collection classes****
Vector and HashTable, sync factory method. добавить подробности.
Problems with synchronized collections
The synchronized collections are thread-safe, but you may sometimes need to use additional client-side locking to guard compound actions: iteration, navigation, and conditional operations such as put-if-absent.
With a synchronized collection, these compound actions are still technically thread-safe even without client-side locking, but they may not behave as you might expect when other threads can concurrently modify the collection.
Например, getSize и взять последнее --- это 2 разных действия.
Поэтому надо дополнительно делать client-side синхронизацию, где локом будет сам list\vector, но тогда любые операцию с этим листом может делать только 1 поток, что немного ухудшает эффективность многопоточности.

можно передать объект для синхоронизации в collect.sync

** for-each loop использует итератор в итоге: Internally, javac generates code that uses an Iterator, repeatedly calling hasNext and next to iterate the List.
The iterators returned by the synchronized collections are not designed to deal with concurrent modification, and they are fail-fast—meaning that if they detect that the collection has changed since iteration began, they throw the unchecked ConcurrentModificationException.
-Iterators are implemented by associating a modification count with the collection: if the modification count changes during iteration, hasNext or next throws ConcurrentModificationException.
-However, this check is done without synchronization, so there is a risk of seeing a stale value of the modification count and therefore that the iterator does not realize a modification has been made. This was a deliberate(преднамеренный, обдуманный компромисс дизайна) design tradeoff to reduce the performance impact of the concurrent modification detection code.

Блокировать коллекцию на время итерации не всегда желательно, т.к. если она большая или операция над каждым элементом довольно долгая, то другим потокам придётся ждать довольно долго.
также есть риск возникновения starvation or deadlock. и также locking collections for significant periods of time hurts application scalability(масштабируемость, расширяемость). т.е. если много потоков будут ждать освобождения лока и бороться за него, то будут простаивать\неэфф ис-ся ресурсы процессора и пропускная спобоность\производительность будет страдать.

Альтернативой для блокировки коллекции при итерации может быть клонирование коллекции, но насколько это выгодный компромисс (клонирование занимает производительность) -- зависит от многих факторов: 
1) размер коллекции
2) сколько работы будет сделано над каждым элементом
3) относительная частота итерации по коллекции, в сравнении с другими операциями с коллекцией
4) требования отзывчивости
5) требования пропускной способоности

*** Hidden iterators СКРЫТЫЕ ИТЕРАТОРЫ ***
Скрытая итерации будет например при выводет коллекции в дебаг сообщение, т.к. будет вызван StringBuilder.append(Object), а в коллекции для каждого её элемента будет вызван toString. И в итоге может быть ConcurrentModificationException. поэтому вывод в дебаг тоже должен происходить с получение лока для этой коллекции (в соответствии с логикой блокировки).

Проблема в том, что чем дальше расстояние между состоянием и блокировкой, которая охраняет это состояние, тем БОЛЬШЕ шанс что кто-то забудет сделать блокировку при работе с этим состоянием.
Just as encapsulating an object’s state makes it easier to preserve its invariants, encapsulating its synchronization makes it easier to enforce its synchronization policy.

-Также итерация косвенно вызывается hashCode и equals методами коллекции. Так может быть если коллекция является ключом или значением в другой коллекции.
-Также the containsAll, removeAll, and retainAll methods, as well as the constructors that take collections as arguments, also iterate the collection. Это может привести к ConcurrentModificationException.

*** 5.2 Concurrent collections ***
Replacing synchronized collections with concurrent collections can offer dramatic scalability improvements with little risk.

1) CopyOnWriteArrayList for cases where traversal(проход по всем элементам) is the dominant operation.
2) The new ConcurrentMap interface adds support for common compound actions such as put-if-absent, replace, and conditional remove.
----------------
Java 5.0 also adds two new collection types, Queue and BlockingQueue. 
1) A Queue is intended to hold a set of elements temporarily while they await processing. 
Several implementations are provided:
[1.A] ConcurrentLinkedQueue, a traditional FIFO queue,
[1.B] PriorityQueue, a (NON CONCURRENT) priority ordered queue. 
QUEUE OPERATIONS DO NOT BLOCK; IF THE QUEUE IS EMPTY, THE RETRIEVAL OPERATION RETURNS NULL. While you can simulate the behavior of a Queue with a List — in fact, LinkedList also implements Queue — the Queue classes were added because eliminating the random-access requirements of List admits more efficient concurrent implementations.
** Что за RANDOMACCESS REQUIREMENTS для List?

2) BlockingQueue extends Queue to add BLOCKING INSERTION AND RETRIEVAL OPERATIONS. 
If the queue is empty, a retrieval blocks until an element is available, and if the queue is full (for bounded queues) an insertion blocks until there is space available. Blocking queues are extremely useful in producer-consumer designs, and are covered in greater detail in Section 5.3.
---------------
Just as ConcurrentHashMap is a concurrent replacement for a synchronized hash-based Map, 
Java 6 adds ConcurrentSkipListMap and ConcurrentSkipListSet, which are concurrent replacements for a synchronized SortedMap or SortedSet (such as TreeMap or TreeSet wrapped with synchronizedMap).
Т.е. ConcurrentSkipListMap and ConcurrentSkipListSet ис-ся для замены TreeMap or TreeSet, обёрнутых в synchronizedMap метод.
------------------------------------------

*** 5.2.1 ConcurrentHashMap ***

THE SYNCHRONIZED COLLECTIONS CLASSES HOLD A LOCK FOR THE DURATION OF EACH OPERATION. 
Some operations, such as HashMap.get() or List.contains(), may involve more work than is initially obvious: 
ЧТОБЫ пройти по всем hash bucket or list и найти нужный объект надо вызывать equals для всех проверяемых кандидатов (equals сам по себе может повлечь большое кол-во вычислений).
Или в hash-based collection при плохом методе hashCode() элементы неравномерно распределятся по бакетам (в самом плохом случае это станет LinkedList).

Поэтому ConcurrentHashMap ис-ет другой механизм блокировки:
it uses an entirely different locking strategy that offers better concurrency and scalability. Instead of synchronizing every method on a common lock, restricting access to a single thread at a time, it uses a FINER-GRAINED LOCKING MECHANISM called LOCK STRIPING (стопорная планка) to allow a greater degree of shared access.

Arbitrarily many READING THREADS can access the map concurrently, READERS can access the map concurrently with WRITERS, and a limited NUMBER OF WRITERS can modify the map concurrently. The result is far higher throughput under concurrent access, with little performance penalty for single-threaded access.
--------
ВСЕ новые concurrent collections предоставляют новый итератор, который не выбрасывает ConcurrentModificationException, thus eliminating the need to lock the collection during iteration.
The iterators returned by ConcurrentHashMap are WEAKLY CONSISTENT instead of FAIL-FAST.
1) FAIL-FAST iterator — meaning that if they detect that the collection has changed since iteration began, they throw the unchecked ConcurrentModificationException.
2) WEAKLY CONSISTENT iterator -- can tolerate (терпеть, выносить, допускать, дозволять) concurrent modification, traverses elements as they existed when the iterator was constructed, and may (but is not guaranteed to) reflect modifications to the collection after the construction of the iterator.

Но в новых коллекциях пошли также на ряд копромисов:
1)  size() and isEmpty(), have been slightly weakened to reflect the concurrent nature of the collection (потому что эти 2 метода far less useful in concurrent environments, потому что зачения этих метода -- это постоянно движущиеся мишени, т.е. они и так постоянно меняются и нет смысла на них полагаться). Поэтому их ослабили, чтобы улучшить производительность других более важных методов, например, get, put, containsKey, and remove.
[1.A] size() is allowed to return an approximation instead of an exact count.

Единственной полезной фичей у старого способа (synchronized Map) осталась возможность залочить мэп для иксклюзивного(единственного) доступа. Это может пригодиться когда:
This might be necessary in unusual cases such as adding several mappings atomically, 
or iterating the Map several times and needing to see the same elements in the same order.

*** 5.2.3    CopyOnWriteArrayList ***
CopyOnWriteArrayList is a concurrent replacement for a synchronized List that offers better concurrency in some common situations and eliminates the need to lock or copy the collection during iteration. (Similarly, CopyOnWriteArraySet is a concurrent replacement for a synchronized Set.)

Условия потокобезопасности для effectively immutable объектов:
as long as an effectively immutable object is properly published, no further synchronization is required when accessing it. 
На этом факте и основывается CopyOnWriteArrayList:
They implement mutability by creating and republishing a new copy of the collection every time it is modified. 
ITERATORS for the copy-on-write collections retain a reference to the backing array that was current at the start of iteration, and since this will never change, they need to synchronize only briefly to ensure visibility of the array contents. ?????????? почему ?????????
As a result, multiple threads can iterate the collection without interference from one another or from threads wanting to modify the collection. The iterators returned by the copy-on-write collections do not throw ConcurrentModificationException and return the elements exactly as they were at the time the iterator was created, regardless of subsequent modifications.
** The returned iterator provides a snapshot of the state of the list when the iterator was constructed. No synchronization is needed while traversing the iterator. The iterator does NOT support the remove method.

-- Тут возникают проблемы с производительсностью, т.к. при записи в лист надо делать его копию ( особенно если размер листа достаточно большой). 
Поэтому COPY-ON-WRITE COLLECTIONS выгодно использовать только когда чаще всего происходит итерация по коллекции, чем изменение коллекции.
Поэтому COPY-ON-WRITE коллекции подходят для MANY EVENT-NOTIFICATION SYSTEMS: 
когда приходят много событий и надо пробегать по списку листенеров чтобы найти обработчик. И при этом чаще надо обрабатывать ивенты, чем удалять и добавлять обработчиков.

*** 5.3 Blocking queues and the producer-consumer pattern ***
Blocking queues provide blocking PUT and TAKE methods as well as the timed equivalents OFFER and POLL. 
If the queue is full,  PUT  BLOCKS until space becomes available; 
if the queue is empty, TAKE BLOCKS until an element is available. 
Queues can be BOUNDED OR UNBOUNDED; unbounded queues are never full, so a put on an unbounded queue never blocks.

Blocking queues support the PRODUCER-CONSUMER DESIGN PATTERN. 
A producer-consumer design separates the identification(отождествление) of work to be done from the execution of that work by placing work items on a "to do" list for later processing, rather than processing them immediately as they are identified. 
The producer-consumer pattern simplifies development because it removes code dependencies between producer and consumer classes, and simplifies workload management by DECOUPLING ACTIVITIES that may produce or consume data at different or variable rates.

One of the most common producer-consumer designs is a THREAD POOL COUPLED WITH A WORK QUEUE; this pattern is embodied(воплощён) in the Executor task execution framework that is the subject of Chapters 6 and 8.

Blocking queues also provide an offer method, which returns a failure status if the item cannot be enqueued. This enables you to create more flexible policies for dealing with overload, such as shedding load, serializing excess work items and writing them to disk, reducing the number of producer threads, or throttling producers in some other manner.

Bounded queues are a powerful resource management tool for building RELIABLE APPLICATIONS: they make your program more robust to overload by throttling activities that threaten to produce more work than can be handled.

While the producer-consumer pattern enables producer and consumer code to be decoupled from each other, their behavior is still coupled indirectly through the shared work queue.
It is tempting to assume that the consumers will always keep up, so that you need not place any bounds on the size of work queues, but this is a prescription for rearchitecting your system later. 
Build resource management into your design early using blocking queues — IT IS A LOT EASIER TO DO THIS UP FRONT THAN TO RETROFIT IT LATER. Blocking queues make this easy for a number of situations, but if blocking queues don't fit easily into your design, you can create other blocking data structures using Semaphore (see Section 5.5.3).

The class library contains several implementations of BlockingQueue:
1,2) LinkedBlockingQueue and ArrayBlockingQueue are FIFO queues, analogous to LinkedList and ArrayList but with better concurrent performance than a synchronized List. 
3) PriorityBlockingQueue is a priority-ordered queue, which is useful when you want to process elements in an order other than FIFO. Just like other sorted collections, PriorityBlockingQueue can compare elements according to their natural order (if they implement Comparable) or using a Comparator.
4) SynchronousQueue, is not really a queue at all, in that it maintains no storage space for queued elements. Instead, it maintains a list of queued threads waiting to enqueue or dequeue an element. In the dish-washing analogy, this would be like having no dish rack, but instead handing the washed dishes directly to the next available dryer. 
-В SynchronousQueue работа по завершению сразу передаётся к потребителю, что гораздо надёжнее, чем сначала положить её в очередь, т.к. неизвестно когда её потом обработают(а тут производитель сразу знает что его результат пошёл обрабатываться дальше). Заодно, не тратятся ресурсы, чтобы положить её в очередь и забрать оттуда. Но при SynchronousQueue всегда должен быть хотя бы 1 свободный потребитель, чтобы ему передать результаты работы.
-Since a SynchronousQueue has no storage capacity, put and take will block unless another thread is already waiting to participate in the handoff. Synchronous queues are generally suitable only when there are enough consumers that there nearly always will be one ready to take the handoff.

--Priority queue represented as a balanced binary heap.
** почитать более подробно про эту структуру
*******************************************************************
A heap is not a sorted structure and can be regarded as partially ordered.
можно сделать heap как tree или как array.
A common implementation of a heap is the binary heap, in which the tree is a complete binary tree
binary tree -- значит, что у каждого нода есть 2 ребёнка.
A binary heap is a heap data structure that takes the form of a binary tree. Binary heaps are a common way of implementing priority queues.
и заполнять хип надо сверху вниз и справа налево. Это необходимое условие, иначе заполнять нельзя.
и потом когда удалять элемент -- то на его место берётся самый правый нижний, и потом опускается на нужное место.
there is no particular relationship among nodes on any given level, even among the siblings. When a heap is a complete binary tree, it has a smallest possible height — a heap with N nodes always has (log N) height. A heap is a useful data structure when you need to remove the object with the highest (or lowest) priority.
Note that, as shown in the graphic, there is no implied ordering between siblings or cousins and no implied sequence for an in-order traversal (as there would be in, e.g., a binary search tree). The heap relation mentioned above applies only between nodes and their parents, grandparents, etc. The maximum number of children each node can have depends on the type of heap, but in many types it is at most two, which is known as a binary heap.
--heapify: create a heap out of given array of elements
--merge (union): joining two heaps to form a valid new heap containing all the elements of both, preserving the original heaps.
--meld: joining two heaps to form a valid new heap containing all the elements of both, destroying the original heaps.
***After an element is inserted into or deleted from a heap, the heap property may be violated and the heap must be balanced by internal operations.
**Balancing a heap is done by sift-up or sift-down operations (swapping elements which are out of order).
***A binary heap is defined as a binary tree with two additional constraints:
 1) Shape property: a binary heap is a complete binary tree; that is, all levels of the tree, except possibly the last one (deepest) are fully filled, and, if the last level of the tree is not complete, the nodes of that level are filled from left to right.
 2) Heap property: the key stored in each node is either greater than or equal to or less than or equal to the keys in the node's children, according to some total order.
*** Над кучей можно выполнять следующие операции:
1) Добавить элемент в кучу. Сложность O ( log ⁡ n ) 
2) Исключить максимальный элемент из кучи. Время работы O ( log ⁡ n ) 
3) Изменить значение любого элемента. Время работы O ( log ⁡ n )

На основе этих операций можно выполнять следующие действия:
4) Превратить неупорядоченный массив элементов в кучу. Сложность O ( n )
5) Отсортировать массив путём превращения его в кучу, а кучи в отсортированный массив. Время работы O ( n log ⁡ n )

*******************************************************************
стэйбл сортировка -- относительный порядок равных элементов сохраняется
********************************************************************

5.3.1 Example: desktop search
Producers and consumers can execute concurrently; if one is I/O-bound and the other is CPU-bound, executing them concurrently yields better overall throughput than executing them sequentially.
While this example uses explicitly managed threads, many producer-consumer designs can be expressed using the Executor task execution framework, which itself uses the producer-consumer pattern.

**** 5.3.2 Serial thread confinement **** (порядковый; последовательный)
The blocking queue implementations in java.util.concurrent all contain sufficient internal synchronization to safely publish objects from a producer thread to the consumer thread.

For mutable objects, producer-consumer designs and blocking queues facilitate(используют, продвигают) SERIAL THREAD CONFINEMENT for handing off ownership of objects from producers to consumers. 
-A thread-confined object is owned EXCLUSIVELY BY A SINGLE THREAD, but that ownership CAN BE "TRANSFERRED" by publishing it safely where only one other thread will gain access to it and ensuring that the publishing thread does not access it after the handoff(пас, передача). The safe publication ensures that the object's state is visible to the new owner, and since the original owner will not touch it again, it is now confined to the new thread. The new owner may modify it freely since it has exclusive access.
-Object pools exploit serial thread confinement, "lending" an object to a requesting thread. 
As long as the pool contains sufficient internal synchronization to publish the pooled object safely, and as long as the clients do not themselves publish the pooled object or use it after returning it to the pool, OWNERSHIP CAN BE TRANSFERRED SAFELY FROM THREAD TO THREAD.
-One could also use other publication mechanisms for transferring ownership of a mutable object, but it is necessary to ensure that only one thread receives the object being handed off. Blocking queues make this easy; 

*** 5.3.3 Deques and work stealing ***
Java 6 also adds another two collection types, Deque (pronounced "deck") and BlockingDeque, that extend Queue and BlockingQueue. 
A DEQUE is a DOUBLE-ENDED QUEUE that allows efficient INSERTION AND REMOVAL FROM BOTH THE HEAD AND THE TAIL. Implementations include ArrayDeque and LinkedBlockingDeque.
-Just as blocking queues lend themselves(быть пригодным/подходящим для) to the producer-consumer pattern, deques lend themselves to a related pattern called WORK STEALING. 
A producer-consumer design has one shared work queue for all consumers; IN A WORK STEALING DESIGN, EVERY CONSUMER HAS ITS OWN DEQUE. If a consumer exhausts the work in its own deque, it can steal work from the TAIL of someone else's deque. 
Work stealing can be more scalable than a traditional producer-consumer design because workers don't contend for a shared work queue; most of the time they access only their own deque, reducing contention. When a worker has to access another's queue, it does so from the tail rather than the head, further reducing contention(соревнование, состязание).

*** 5.4 Blocking and interruptible methods ***
Threads may block, or pause, for several reasons: waiting for I/O completion, waiting to acquire a lock, waiting to wake up from Thread.sleep, or waiting for the result of a computation in another thread. 
When a thread blocks, it is usually suspended and placed in one of the blocked thread states (BLOCKED, WAITING, or TIMED_WAITING). 
The distinction between a blocking operation and an ordinary operation that (только, просто; единственно)merely takes a long time to finish is that a blocked thread must wait for an event that is beyond its control before it can proceed — the I/O completes, the lock becomes available, or the external computation finishes. When that external event occurs, the thread is placed back in the RUNNABLE state and becomes eligible again for scheduling.

The put and take methods of BlockingQueue throw the checked InterruptedException, as do a number of other library methods such as Thread.sleep. 
When a method can throw InterruptedException, it is telling you that it is a blocking method, and further that if it is interrupted, IT WILL MAKE AN EFFORT TO STOP BLOCKING EARLY.

INTERRUPTION is a COOPERATIVE mechanism. механизм сотрудничества
One thread CANNOT FORCE ANOTHER TO STOP what it is doing and do something else; 
when thread A interrupts thread B, A IS MERELY REQUESTING THAT B STOP WHAT IT IS DOING WHEN IT GETS TO A CONVENIENT STOPPING POINT—if it feels like it. 
While there is nothing in the API or language specification that demands any specific application-level semantics for interruption, the MOST SENSIBLE USE FOR INTERRUPTION IS TO CANCEL AN ACTIVITY. Blocking methods that are responsive to interruption make it easier to cancel long-running activities on a timely basis.

When your code calls a method that throws InterruptedException, then YOUR METHOD IS A BLOCKING METHOD TOO, and MUST have a plan for RESPONDING TO INTERRUPTION. 
For library code, there are basically two choices:
1) PROPAGATE THE INTERRUPTED EXCEPTION. 
This is often the most sensible policy if you can get away with it—just propagate the InterruptedException to your caller. This could involve not catching InterruptedExcepti on, or catching it and throwing it again after performing some brief activity-specific cleanup.
2) RESTORE THE INTERRUPT. 
Sometimes you cannot throw InterruptedException, for instance when your code is part of a Runnable. In these situations, you must catch InterruptedException and restore the interrupted status by calling interrupt on the current thread, so that code higher up the call stack can see that an interrupt was issued, as demonstrated in Listing 5.10. [Thread.currentThread().interrupt();]

You can get much more sophisticated with interruption, but these two approaches should work in the vast majority of situations. But there is one thing you should NOT do with InterruptedException — [!! DO NOT] CATCH IT AND DO NOTHING IN RESPONSE. 
This deprives(лишать; отбирать, отнимать, не допускать) code higher up on the call stack of the opportunity to act on the interruption, because the evidence that the thread was interrupted is lost. 
The only situation in which it is acceptable to swallow an interrupt is when you are extending Thread and therefore control all the code higher up on the call stack. Cancellation and interruption are covered in greater detail in Chapter 7.
--------------------------------------------------------------------------------
*** 5.5 Synchronizers *** 07.01.2016
A SYNCHRONIZER is any object that coordinates the control flow of threads based on its state. 
SYNCHRONIZER -- любой объект, который координирует ход выполнения потоков, в зависимости от своего состояния.

Типы\виды\разновидности синхронизаторов:
1) Blocking queues can act as synchronizers
2) semaphores,
3) barriers, 
4) latches,
5) FutureTask also acts like a latch. 
6) EXCHANGER -- another form of barrier.

All synchronizers share certain STRUCTURAL PROPERTIES: they encapsulate STATE that:
1) determines whether threads arriving at the synchronizer should be ALLOWED TO PASS or FORCED TO WAIT, 
2) provide methods to MANIPULATE that STATE, 
3) provide methods to WAIT EFFICIENTLY for the synchronizer TO ENTER the desired state. (Эфективно ждать момента, пока синхронизатор придёт в нужное состояние.)

*** 5.5.1 Latches (триггер, защёлка, клапан) *** CountDownLatch *** ОДНОРАЗОВЫЕ ЗАЩЁЛКИ
*** Как ОДНОРАЗОВЫЙ ЗАМОК НА ВОРОТАХ, чтобы открыть его -- надо ОПУСТИТЬ ВСЕ ЗУБЧИКИ. --но замок хрупкий, поэтому после 1 раза все зубчики сломались и больше он никого не сдержит --- ***

A latch is a synchronizer that can delay(задержать, приостановить) the progress of threads until it reaches its terminal state(конечное, последнее, заключительное состояние).

LATCHES ARE SINGLE-USE OBJECTS; 
ONCE A LATCH ENTERS THE TERMINAL STATE, IT CANNOT BE RESET.

A latch acts as a GATE: until the latch reaches the terminal state the gate is closed and no thread can pass, and in the terminal state the gate opens, allowing all threads to pass. 
ONCE THE LATCH REACHES THE TERMINAL STATE, IT CANNOT CHANGE STATE AGAIN, SO IT REMAINS OPEN FOREVER.

Latches can be used to ensure that certain activities do not proceed until other one-time activities complete, such as:
1) Ensuring that a computation does not proceed until resources it needs have been initialized.
2) Ensuring that a service does not start until other services on which it depends have started.
3) Waiting until all the parties involved in an activity, for instance the players in a multi-player game, are ready to proceed.

CountDownLatch is a flexible latch implementation that can be used in any of these situations; 
it allows one or more threads to wait for a set of events to occur. 

The latch state consists of a counter initialized to a positive number, representing the number of events to wait for.

The .countDown() method decrements the counter, indicating that an event has occurred, and the await methods wait for the counter to reach zero, which happens when all the events have occurred. If the counter is nonzero on entry, await blocks until the counter reaches zero, the waiting thread is interrupted, or the wait times out.

TestHarness.JAVA -- Presumably, we wanted to measure how long it takes to run a task n times concurrently.
The first thing each worker thread does is wait on the starting gate; this ensures that none of them starts working until they all are ready to start. 
The last thing each does is count down on the ending gate; this allows the master thread to wait efficiently until the last of the worker threads has finished, so it can calculate the elapsed time.

*** 5.5.2 FutureTask ***
FutureTask also acts like a latch.
FutureTask implements Future, which describes an abstract result-bearing computation(приносящее результат вычисление).

A Future represents the result of an asynchronous computation.

A computation represented by a FutureTask is implemented with a Callable, the result-bearing equivalent of Runnable, and can be in ONE OF THREE STATES: 
1) waiting to run, 
2) running, 
3) completed. 
Completion subsumes(включает) ALL THE WAYs a computation can complete, including normal completion, cancellation, and exception. 

ONCE A FUTURETASK ENTERS THE COMPLETED STATE, IT STAYS IN THAT STATE FOREVER.

The behavior of Future.get() depends on the state of the task: 
1) If it is completed, get returns the result immediately, 
2) and otherwise blocks until the task transitions to the completed state and then returns the result.
3) or throws an exception. 
FutureTask conveys(передаёт) the result from the thread executing the computation to the thread(s) retrieving the result; the specification of FutureTask guarantees that this transfer constitutes a safe publication of the result.

--- [eı`sıŋkrənəs] эйс-И-нкронэс ---
FutureTask is used by the Executor framework to represent:
1) asynchronous tasks
2) any potentially lengthy computation that can be started before the results are needed. 

Preloader.java -- creates a FutureTask that describes the task of loading product information from a database and a thread in which the computation will be performed. 
It provides a start method to start the thread, since it is inadvisable to start a thread from a constructor or static initializer. 
When the program later needs the ProductInfo, it can call get(), which returns the loaded data if it is ready, or waits for the load to complete if not.

--Tasks described by Callable can THROW checked and unchecked exceptions, and any code can throw an Error. Whatever the task code may throw, it is wrapped in an ExecutionException and rethrown from Future.get(). 
--This complicates code that calls get(), not only because it must deal with the possibility of ExecutionException (and the unchecked CancellationException), but also because the cause of the ExecutionException is returned as a Throwable, which is inconvenient to deal with.

--When get throws an ExecutionException in Preloader, the cause will fall into one of three categories: a checked exception thrown by the Callable, a RuntimeException, or an Error. We must handle each of these cases separately.

*** 5.5.3 Semaphores *** СЕМАФОРЫ
Семафоры бывают двоичные (binary semaphore) и подсчитывающие (counting semaphore), а также именованные и неименованные.

Семафор обычно представляет собой целочисленную переменную или объект, над которыми разрешается производить три операции: инициализацию, инкремент и декремент. В зависимости от того, как они определены, декремент может означать блокировку процесса или ресурса, а инкремент - его разблокировку. 

Counting semaphores are used to control the number of activities that can access a certain resource or perform a given action at the same time. 
Counting semaphores can be used to implement resource pools or to impose a bound(наложить ограничение) on a collection.

A Semaphore manages a set of VIRTUAL PERMITS; the initial number of permits is passed to the Semaphore constructor.
Activities can acquire permits (as long as some remain) and release permits when they are done with them. If no permit is available, acquire blocks until one is (пока хотя бы 1 разрешение не станет доступным) (or until interrupted or the operation times out).
The release method returns a permit to the semaphore.

---The implementation has no actual permit objects, and Semaphore does not associate dispensed permits with threads, so a permit acquired in one thread can be released from another thread. You can think of acquire as consuming a permit and release as creating one; a Semaphore is not limited to the number of permits it was created with.---
A degenerate case of a counting semaphore is a binary semaphore, a Semaphore with an initial count of one. A binary semaphore can be used as a mutex with nonreentrant locking semantics; whoever holds the sole permit holds the mutex.

Semaphores are useful for implementing resource pools such as database connection pools. While it is easy to construct a fixed-sized pool that fails if you request a resource from an empty pool, what you really want is to block if the pool is empty and unblock when it becomes nonempty again.

*** 5.5.4 Barriers *** ждёт всё кол-во участников и пропускает их через турникет. *** МНОГОРАЗОВЫЙ
*** как туникеты на скачках -- все лошади подтянулись -- стартовать забег, а турникет сразу после этого закрывается и ждёт новую группу лошадей ***

Barriers are similar to latches in that they block a group of threads until some event has occurred. 
The key difference is that with a barrier, ALL THE THREADS MUST COME TOGETHER AT A BARRIER POINT AT THE SAME TIME IN ORDER TO PROCEED. 
** LATCHES ARE FOR WAITING FOR EVENTS; BARRIERS ARE FOR WAITING FOR OTHER THREADS. 
A barrier implements the protocol some families use to rendezvous during a day at the mall: "Everyone meet at McDonald's at 6:00; once you get there, stay there until everyone shows up, and then we'll figure out what we're doing next."

- CyclicBarrier allows a fixed number of parties to rendezvous REPEATEDLY at a barrier point and is useful in PARALLEL ITERATIVE ALGORITHMS that break down a problem into a fixed number of independent subproblems.
-- Threads call await when they reach the barrier point, and await blocks until all the threads have reached the barrier point. If all threads meet at the barrier point, the barrier has been successfully passed, in which case all threads are released and the barrier is reset so it can be used again. 
--- If a call to await times out or a thread blocked in await is interrupted, then the barrier is considered broken and all outstanding calls to .await() terminate with BrokenBarrierException. If the barrier is successfully passed, .await() returns a unique arrival index for each thread, which can be used to "ELECT" a leader that takes some special action in the next iteration. 
---- CyclicBarrier also lets you pass a barrier action to the constructor; this is a Runnable that is executed (in one of the subtask threads) when the barrier is successfully passed but before the blocked threads are released. 

********** When using a CyclicBarrier, the assumption is that you specify the number of waiting threads that trigger the barrier. If you specify 5, you must have at least 5 threads to call await().

When using a CountDownLatch, you specify the number of calls to countDown() that will result in all waiting threads being released. This means that you can use a CountDownLatch with only a single thread.

!!! The CyclicBarrier uses an ALL-OR-NONE breakage model for failed synchronization attempts: If a thread leaves a barrier point prematurely(преждевременно) because of interruption, failure, or timeout, ALL OTHER THREADS waiting at that barrier point will also leave abnormally via BrokenBarrierException (or InterruptedException if they too were interrupted at about the same time). 
************

CellularAutomata.java
https://bitstorm.org/gameoflife/

Another form of barrier is EXCHANGER - a TWO-PARTY BARRIER in which the parties exchange data at the barrier point.

- Exchangers are useful when the parties perform asymmetric activities, for example when one thread fills a buffer with data and the other thread consumes the data from the buffer; 
these threads could use an Exchanger to meet and exchange a full buffer for an empty one. 
When two threads exchange objects via an Exchanger, the exchange constitutes a safe publication of both objects to the other party.
The timing of the exchange depends on the responsiveness requirements of the application.
---------------------------------------------------

*** 5.6 Building an efficient, scalable result cache ***
we'd like to create a Computable wrapper that remembers the results of previous computations and encapsulates the caching process. (This technique is known as MEMOIZATION.)
** КАКИЕ ПРОБЛЕМЫ С КЭШЕМ И КАК ИХ РЕШАТЬ ??
*1* Memoizer1
*2* Memoizer2 in Listing 5.17 improves on the awful concurrent behavior of Memoizer1 by replacing the HashMap with a ConcurrentHashMap. Since ConcurrentHashMap is thread-safe, there is no need to synchronize when accessing the backing Map, thus eliminating the serialization induced by synchronizing compute in Memoizer1.
But it still has some defects as a cache — there is a window of vulnerability in which two threads calling compute at the same time could end up computing the same value.
(The problem with Memoizer2 is that if one thread starts an expensive computation, other threads are not aware that the computation is in progress and so may start the same computation).

*3* Для этого надо дать понять, что такая-то задача уже выполняется, и второму с такой же задачей надо лишь продождать результатов и получить их. Поэтому здесь надо ис-ть FutureTask.
--FutureTask represents a computational process that may or may not already have completed. FutureTask.get() returns the result of the computation immediately if it is available; 
otherwise it blocks until the result has been computed and then returns it.
--Memoizer3 first checks to see if the appropriate calculation has been started (as opposed to finished, as in Memoizer2). If not, it creates a FutureTask, registers it in the Map, and starts the computation; otherwise it waits for the result of the existing computation. The result might be available immediately or might be in the process of being computed—but this is transparent to the caller of Future.get().

*4* there is still a small window of vulnerability(уязвимость; ранимость) in which two threads might compute the same value. This window is far smaller than in Memoizer2, but because the if block in compute is still a NONATOMIC CHECK-THEN-ACT sequence, it is possible for two threads to call compute with the same value at roughly the same time, both see that the cache does not contain the desired value, and both start the computation. This unlucky timing is illustrated in Figure 5.4.

Memoizer in Listing 5.19 takes advantage of the atomic putIfAbsent() method of ConcurrentMap, closing the window of vulnerability in Memoizer3.

-- Caching a Future instead of a value creates the POSSIBILITY of CACHE POLLUTION: 
if a computation is cancelled or fails, future attempts to compute the result will also indicate cancellation or failure. 
To avoid this, Memoizer removes the Future from the cache if it detects that the computation was cancelled; 
it might also be desirable to remove the Future upon detecting a RuntimeException if the computation might succeed on a future attempt.
-- Memoizer also does not address CACHE EXPIRATION, but this could be accomplished by using a subclass of FutureTask that associates an expiration time with each result and periodically scanning the cache for expired entries. 
(Similarly, it does not address CACHE EVICTION, where old entries are removed to make room for new ones so that the cache does not consume too much memory.)

что такое кэш - переиспользование результатов вычисления.
Что дожно быть у идеального кэша:
1) не считать одно и то же дважды (гарантировать что каждое зн-е будет вычислено только 1 раз)
2) в многопоточном приложении -- распределять вычисления на много потоков, если в 1 уже вычилсяется нужно зн-е то другие кому надо не запускают новое а ждут результатов первого.
3) CACHE EXPIRATION - Удалять истёкшие по валидности значения(либо обновлять эти значения). Например, курс валют каждый день.
4) CACHE EVICTION - освобождать кэш от старых [может быть неиспользуемых значений]. чтобы кэш не разрастался безконтрольно.