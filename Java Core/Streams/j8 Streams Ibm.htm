<!DOCTYPE html> 
<html lang="en"> 
<head> 	
<meta charset="UTF-8"> 	
<title>j8 Streams Ibm</title>     
<link rel="stylesheet" href="../../Git Guide/grey.css">     
<style type="text/css">     	.code { 		font-family: "Trebuchet MS",Tahoma,Arial; 		font-size: 18px; 		font-weight: bold; 		border: 1px solid #000; 		background-color: #999; 		padding: 5px; 	}     
</style> 
</head> 
<body> 
<a href="https://www.ibm.com/developerworks/library/?search_by=Java+Streams,+Part">ibm src</a>  
<h2>Part 1 An introduction to the java.util.stream library</h2>
<div>
	<h3>Приемущества использования Stream</h3>
	<ol>
		<li>The java.util.stream library provides a simple and flexible means to express possibly-parallel functional-style queries on various data sources, including collections, arrays, generator functions, ranges, or custom data structures. </li>
		<li>The facilities for aggregation are one of the most useful and flexible parts of the Streams library. </li>
		<li> 
			In many cases, the library figures out how to perform queries efficiently, with no help from the user. 
			<br>
			the performance of Streams out of the box is generally good (sometimes even better than the corresponding imperative code)
			<br>
			Parallelism is a trade-off of using more compute resources in the hope of getting a speedup. While in theory we can speed up a problem by a factor of N by using N cores, reality usually falls far short of this goal.
		</li>
		<li></li>
	</ol>
</div>
 <div class="ibm-col-6-4 cye-lm-tag"> 
 <p class="dw-article-series-head cye-lm-tag">Java Streams, Part 1</p>
         <h1 id="ibm-pagetitle-h1" class="ibm-h1 cye-lm-tag">An introduction to the java.util.stream library</h1>
<p class="dw-article-subhead cye-lm-tag"> Run functional-style queries on collections and other data sets </p>
         <!-- Article Top Bar --> <div class="dw-article-authordate"><span class="dw-article-author cye-lm-tag"><a href="https://twitter.com/BrianGoetz">Brian Goetz</a></span><br><span class="dw-article-pubdate cye-lm-tag">Published on May 09,  2016</span><span class="dw-article-divider cye-lm-tag">/</span><span class="dw-article-updated cye-lm-tag">Updated: July 06,  2016</span></div>     </div>     <!-- Social -->     <div class="ibm-col-6-2 ibm-col-medium-6-4 ibm-col-small-6-2 dw-article-social">         <!-- Sharing links -->          </div>         </div>          <div id="dw-series-container" style="display: block;"><h3 class="ibm-h3" id="dw-series-heading">Content series:</h3>
<div data-widget="showhide" data-type="panel" class="ibm-show-hide ibm-widget-processed"><div class="ibm-container-body" id="dw-series-links"><ul id="dw-series-list"><li class="dw-series-item"><a href="https://www.ibm.com/developerworks/java/library/j-java-streams-1-brian-goetz/index.html">Part 1: An introduction to the java.util.stream library</a></li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-2-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 2: Aggregating with Streams</a></li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-3-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 3: Streams under the hood</a></li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-4-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 4: From concurrent to parallel</a></li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-5-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 5: Parallel stream performance</a></li></ul></div></div></div>         <!-- Article Body -->                  <p class="cye-lm-tag">The major new language feature in Java SE 8 was <em>lambda expressions</em>. You can think of a lambda expression as an anonymous method; like methods, lambdas have typed parameters, a body, and a return type. But the real news wasn't lambda expressions themselves, but what they enable. Lambdas make it easy to <strong>express behavior as     data</strong>, which in turn makes it possible to develop more-expressive and more-powerful libraries.</p>
<p class="cye-lm-tag">One such library, also introduced in Java SE 8, is the <code>java.util.stream</code> package (Streams), which enables the concise and declarative expression of possibly-parallel bulk operations on various data sources. Libraries like Streams could have been written in earlier versions of Java, but without a compact behavior-as-data idiom they would have been so cumbersome to use that no one would have wanted to use them. You can consider Streams to be the first library to take advantage of the power of lambda expressions in Java, but there's nothing magical about it (though it is tightly integrated into the core JDK libraries). Streams isn't part of the language — it's a carefully designed library that takes advantage of some newer language features.</p>
<p class="cye-lm-tag">This article is the first in a series that explores the <code>java.util.stream</code> library in depth. This installment introduces you to the library and gives you an overview of its advantages and design principles. In subsequent installments, you learn how to use streams to aggregate and summarize data and get a look at the library's internals and performance optimizations.</p>
<h2 id="N1007F" class="ibm-h2">Querying with streams</h2>
<p class="cye-lm-tag">One of the most common uses of streams is to represent <em>queries</em> over data in collections. Listing 1 shows an example of a simple stream pipeline. The pipeline takes a collection of transactions modeling a purchase between a buyer and a seller, and computes the total dollar value of transactions by sellers living in New York.</p>
<h5 id="listing1" class="ibm-h5">Listing 1. A simple stream pipeline</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_865408" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">int totalSalesFromNY</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">= txns.stream()</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.filter(t -&gt; t.getSeller().getAddr().getState().equals("NY"))</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.mapToInt(t -&gt; t.getAmount())</code></div><div class="line number5 index4 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.sum();</code></div></div></td></tr></tbody></table>
</div></div></div></span><div class="ibm-pull-quote ibm-h3"><blockquote><p class="cye-lm-tag"><em class="dw-pullquote"><span class="dw-pullquote-open cye-lm-tag">“</span>Streams exploit that most powerful of computing     principles: composition.<span class="dw-pullquote-close cye-lm-tag">”</span></em></p>
</blockquote></div><p class="cye-lm-tag">The <code>filter()</code> operation selects only transactions with sellers from New York. The <code>mapToInt()</code> operation selects the transaction amount for the desired transactions. And the terminal <code>sum()</code> operation adds up these amounts.</p>
<p class="cye-lm-tag">Although this example is pretty and easy to read, detractors might point out that the imperative (<code>for</code>-loop) version of this query is also simple and takes fewer lines of code to express. But the problem doesn't have to get much more complicated for the benefits of the stream approach to become evident. Streams exploit that most powerful of computing principles: composition. By composing complex operations out of simple building blocks (filtering, mapping, sorting, aggregation), streams queries are more likely to remain straightforward to write and read as the problem gets complicated than are more ad-hoc computations on the same data sources.</p>
<p class="cye-lm-tag">As a more complex query from the same domain as Listing 1, consider "Print the names of sellers in transactions with buyers over age 65, sorted by name." Writing this query the old-fashioned (imperative) way might yield something like Listing 2.</p>
<h5 id="listing2" class="ibm-h5">Listing 2. Ad-hoc query over a collection</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_842145" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">Set&lt;</code><code class="htmlscript plain">Seller</code><code class="htmlscript plain">&gt; sellers = new HashSet&lt;&gt;();</code></div><div class="line number2 index1 alt1"><code class="htmlscript plain">for (Txn t : txns) {</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">if (t.getBuyer().getAge() &gt;= 65)</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">sellers.add(t.getSeller());</code></div><div class="line number5 index4 alt2"><code class="htmlscript plain">}</code></div><div class="line number6 index5 alt1"><code class="htmlscript plain">List&lt;</code><code class="htmlscript plain">Seller</code><code class="htmlscript plain">&gt; sorted = new ArrayList&lt;&gt;(sellers);</code></div><div class="line number7 index6 alt2"><code class="htmlscript plain">Collections.sort(sorted, new Comparator&lt;</code><code class="htmlscript plain">Seller</code><code class="htmlscript plain">&gt;() {</code></div><div class="line number8 index7 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">public int compare(Seller a, Seller b) {</code></div><div class="line number9 index8 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">return a.getName().compareTo(b.getName());</code></div><div class="line number10 index9 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">}</code></div><div class="line number11 index10 alt2"><code class="htmlscript plain">});</code></div><div class="line number12 index11 alt1"><code class="htmlscript plain">for (Seller s : sorted)</code></div><div class="line number13 index12 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">System.out.println(s.getName());</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">Although this query is only slightly more complex than the first one, it's clear that the organization and readability of the resulting code under the imperative approach have already started to fall apart. The first thing the reader sees is neither the starting nor ending point of the computation; it's the declaration of a throwaway intermediate result. To read this code, you need to mentally buffer a lot of context before figuring out what the code actually does. Listing 3 shows how you might rewrite this query using Streams.</p>
<h5 id="listing3" class="ibm-h5">Listing 3. Query from Listing 2, expressed using     Streams</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_617952" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">txns.stream()</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.filter(t -&gt; t.getBuyer().getAge() &gt;= 65)</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.map(Txn::getSeller)</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.distinct()</code></div><div class="line number5 index4 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.sorted(comparing(Seller::getName))</code></div><div class="line number6 index5 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.map(Seller::getName)</code></div><div class="line number7 index6 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.forEach(System.out::println);</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">The code in Listing 3 is far easier to read, because the user is neither distracted with "garbage" variables — like <code>sellers</code> and <code>sorted</code>— and doesn't have to keep track of a lot of context while reading the code; the code reads almost exactly like the problem statement. Code that's more readable is also less error prone, because maintainers are more likely to be able to correctly discern at first glance what the code does.</p>
<p class="cye-lm-tag">The design approach taken by libraries like Streams leads to a practical separation of concerns. The client is in charge of specifying the "what" of a computation, but the library has control over the "how." This separation tends to parallel the distribution of expertise; the client writer generally has better understanding of the problem domain, whereas the library writer generally has more expertise in the algorithmic properties of the execution. The key enabler for writing libraries that allow this sort of separation of concerns is the ability to pass behavior as easily as passing data, which in turn enables APIs where callers can describe the structure of a complex calculation, and then get out of the way while the library chooses the execution strategy.</p>
<h2 id="N100D6" class="ibm-h2">Anatomy of a stream pipeline</h2>
<p class="cye-lm-tag">All stream computations share a common structure: They have a <em>stream     source</em>, zero or more <em>intermediate operations</em>, and a single <em>terminal operation</em>. The elements of a stream can be object references (<code>Stream&lt;String&gt;</code>) or they can be primitive integers (<code>IntStream</code>), longs (<code>LongStream</code>), or doubles (<code>DoubleStream</code>).</p>
<p class="cye-lm-tag">Because most of the data that Java programs consume is already stored in collections, many stream computations use collections as their source. The <code>Collection</code> implementations in the JDK have all been enhanced to act as efficient stream sources. But other possible stream sources also exist — such as arrays, generator functions, or built-in factories such as numeric ranges — and (as shown in the <a href="http://www.ibm.com/developerworks/library/j-java-streams-3-brian-goetz/index.html">third installment</a> in this series)  it's possible to write custom stream adapters so that any data source can act as a stream source. Table 1 shows some of the stream-producing methods in the JDK. </p>
<h5 id="table1" class="ibm-h5">Table 1. Stream sources in the JDK</h5>
<table border="0" cellpadding="0" cellspacing="0" class="ibm-data-table"><thead xmlns:dw="http://www.ibm.com/developerWorks/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><tr><th scope="col">Method</th><th scope="col">Description</th></tr></thead><tbody xmlns:dw="http://www.ibm.com/developerWorks/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><tr><td><code>Collection.stream()</code></td><td>Create a stream from the elements of a collection.</td></tr><tr><td><code>Stream.of(T...)</code></td><td>Create a stream from the arguments passed to the factory method.</td></tr><tr><td><code>Stream.of(T[])</code></td><td>Create a stream from the elements of an array.</td></tr><tr><td><code>Stream.empty()</code></td><td>Create an empty stream.</td></tr><tr><td><code>Stream.iterate(T first, BinaryOperator&lt;T&gt; f)</code></td><td>Create an infinite stream consisting of the sequence <code>first, f(first), f(f(first)), ...</code></td></tr><tr><td><code>Stream.iterate(T first, Predicate&lt;T&gt; test, BinaryOperator&lt;T&gt; f)</code></td><td>(Java 9 only) Similar to <code>Stream.iterate(T first, BinaryOperator&lt;T&gt; f)</code>, except the stream terminates on the first elements for which the test predicate returns <code>false</code>.</td></tr><tr><td><code>Stream.generate(Supplier&lt;T&gt; f)</code></td><td>Create an infinite stream from a generator function.</td></tr><tr><td><code>IntStream.range(lower, upper)</code></td><td>Create an <code>IntStream</code> consisting of the elements from lower to upper, exclusive.</td></tr><tr><td><code>IntStream.rangeClosed(lower, upper)</code></td><td>Create an <code>IntStream</code> consisting of the elements from lower to upper, inclusive.</td></tr><tr><td><code>BufferedReader.lines()</code></td><td>Create a stream consisting of the lines from a <code>BufferedReader.</code></td></tr><tr><td><code>BitSet.stream()</code></td><td>Create an <code>IntStream</code> consisting of the indexes of the set bits in a <code>BitSet</code>.</td></tr><tr><td><code>CharSequence.chars()</code></td><td>Create an <code>IntStream</code> corresponding to the chars in a <code>String</code>.</td></tr></tbody></table>
<p class="cye-lm-tag">Intermediate operations — such as <code>filter()</code> (selecting elements matching a criterion), <code>map()</code> (transforming elements according to a function), <code>distinct()</code> (removing duplicates), <code>limit()</code> (truncating a stream at a specific size), and <code>sorted()</code>— transform a stream into another stream. Some operations, such as <code>mapToInt()</code>, take a stream of one type and return a stream of a different type; the example of <a href="#listing1">Listing 1</a> starts as a <code>Stream&lt;Transaction&gt;</code> and later switches to an <code>IntStream</code>. Table 2 shows some of the intermediate stream operations.</p>
<h5 id="table2" class="ibm-h5">Table 2. Intermediate stream operations</h5>
<table border="0" cellpadding="0" cellspacing="0" class="ibm-data-table"><thead xmlns:dw="http://www.ibm.com/developerWorks/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><tr><th scope="col">Operation</th><th scope="col">Contents</th></tr></thead><tbody xmlns:dw="http://www.ibm.com/developerWorks/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><tr><td><code>filter(Predicate&lt;T&gt;)</code></td><td> The elements of the stream matching the predicate</td></tr><tr><td><code>map(Function&lt;T, U&gt;)</code></td><td> The result of applying the provided function to the elements of the stream</td></tr><tr><td><code>flatMap(Function&lt;T, Stream&lt;U&gt;&gt;</code></td><td> The elements of the streams resulting from applying the provided stream-bearing function to the elements of the stream</td></tr><tr><td><code>distinct()</code></td><td> The elements of the stream, with duplicates removed</td></tr><tr><td><code>sorted()</code></td><td> The elements of the stream, sorted in natural order</td></tr><tr><td><code>Sorted(Comparator&lt;T&gt;)</code></td><td> The elements of the stream, sorted by the provided comparator</td></tr><tr><td><code>limit(long)</code></td><td> The elements of the stream, truncated to the provided length</td></tr><tr><td><code>skip(long)</code></td><td> The elements of the stream, discarding the first N elements</td></tr><tr><td><code>takeWhile(Predicate&lt;T&gt;)</code></td><td> (Java 9 only) The elements of the stream, truncated at the first element for which the provided predicate is not <code>true</code></td></tr><tr><td><code>dropWhile(Predicate&lt;T&gt;)</code></td><td> (Java 9 only) The elements of the stream, discarding the initial segment of elements for which the provided predicate is <code>true</code></td></tr></tbody></table>
<p class="cye-lm-tag">Intermediate operations are always <em>lazy</em>: Invoking an intermediate operation merely sets up the next stage in the stream pipeline but doesn't initiate any work. Intermediate operations are further divided into     <em>stateless</em> and <em>stateful</em> operations. <br>     <b>Stateless</b> operations (such as <code>filter()</code> or <code>map()</code>) can operate on each element independently, <br>whereas <b>stateful</b> operations (such as <code>sorted()</code> or <code>distinct()</code>) can incorporate state from previously seen elements that affects the processing of other elements.</p>
<p class="cye-lm-tag">The processing of the data set <b>begins</b> <u>when a terminal operation is executed</u>, such as a reduction (<code>sum()</code> or <code>max()</code>), application (<code>forEach()</code>), or search (<code>findFirst()</code>) operation. <br><b>Terminal operations</b> produce a result or a side effect. When a terminal operation is executed, the stream pipeline is terminated, and if you want to traverse the same data set again, you can set up a new stream pipeline. Table 3 shows some of the terminal stream operations. </p>
<h5 id="table3" class="ibm-h5">Table 3. Terminal stream operations</h5>
<table border="0" cellpadding="0" cellspacing="0" class="ibm-data-table"><thead xmlns:dw="http://www.ibm.com/developerWorks/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><tr><th scope="col">Operation</th><th scope="col">Description</th></tr></thead><tbody xmlns:dw="http://www.ibm.com/developerWorks/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><tr><td><code>forEach(Consumer&lt;T&gt; action)</code></td><td> Apply the provided action to each element of the stream.</td></tr><tr><td><code>toArray()</code></td><td> Create an array from the elements of the stream.</td></tr><tr><td><code>reduce(...)</code></td><td> Aggregate the elements of the stream into a summary value.</td></tr><tr><td><code>collect(...)</code></td><td> Aggregate the elements of the stream into a summary result container.</td></tr><tr><td><code>min(Comparator&lt;T&gt;)</code></td><td> Return the minimal element of the stream according to the comparator.</td></tr><tr><td><code>max(Comparator&lt;T&gt;)</code></td><td> Return the maximal element of the stream according to the comparator.</td></tr><tr><td><code>count()</code></td><td> Return the size of the stream.</td></tr><tr><td><code>{any,all,none}Match(Predicate&lt;T&gt;) <br>X.anyMatch(..) <br>Y.allMatch(..) <br>Z.noneMatch(..) </code> </td>  <td> Return whether any/all/none of the elements of the stream match the provided predicate.</td></tr><tr><td><code>findFirst()</code></td><td> Return the first element of the stream, if present.</td></tr><tr><td><code>findAny()</code></td><td> Return any element of the stream, if present.</td></tr></tbody></table>
<h2 id="N10258" class="ibm-h2">Streams versus collections</h2>
<p class="cye-lm-tag">While streams can resemble collections superficially [поверхностно, бегло]— you might think of both as containing data — in reality they differ significantly. <br>A <b>collection</b> is a data structure; its main concern is <u>the organization of data in memory</u>, and a <u>collection persists over a period of time</u>. <br> A collection might often be used as the source or target for a stream pipeline, but a stream's focus is on <strong>computation</strong>, not data. The data comes from elsewhere (a collection, array, generator function, or I/O channel) and is processed through a pipeline of computational steps to produce a result or side effect, <u>at which point the stream is finished.</u> <br>Streams provide no storage for the elements that they process, and the lifecycle of a stream is more like a <b>point in time</b> — the invocation of the terminal operation. <br>Unlike collections, <b>streams</b> can also be <b>infinite</b>; correspondingly, some operations (<code>limit()</code>, <code>findFirst()</code>) are     <em>short-circuiting</em>[Короткое замыкание] and can operate on infinite streams with finite computation.</p>
<p class="cye-lm-tag">Collections and streams also differ <b>in the way that their operations are executed</b>. <br>
<b>Operations on collections</b><u> are eager and mutative</u>; when the <code>remove()</code> method is called on a <code>List</code>, after the call returns, you know that the list state was modified to reflect the removal of the specified element. <br><b>For streams</b>, <u>only the terminal operation is eager; the others are lazy. </u><br><br><b>Stream operations</b> represent a <u>functional transformation on their input</u> (also a stream), <u><b>rather than</b> a mutative operation on a data set</u>:<br> (filtering a stream <b>produces a new stream</b> whose elements are a subset of the input stream but <u>doesn't remove any elements from the source</u>).</p>
<p class="cye-lm-tag">Expressing a stream pipeline as a sequence of functional transformations enables several useful execution strategies, such as <em>laziness</em>,     <em>short circuiting</em>, and <em>operation fusion</em>. 
<ul>
	<li>parallelism</li><br>
	<li>laziness</li><br>
	<li><b>Short-circuiting</b> enables a pipeline to terminate successfully without examining all the data; queries such as "find the first transaction over $1,000" needn't examine any more transactions after a match is found. </li><br>
	<li><b>Operation fusion</b> means that multiple operations can be executed in a single pass on the data; in the example in <a href="#listing1">Listing     1</a>, the three operations are <b>combined into a single pass on the data</b> — rather than first selecting all the matching transactions, then selecting all the corresponding amounts, and then adding them up.</li>
</ul>

</p>

<p class="cye-lm-tag">The <b>imperative version </b>[т.е. стандартный подход с циклами for и временными коллекциями для хранения промежутоных результатов] of queries like the ones in <a href="#listing1">Listing 1</a> and <a href="#listing3">Listing 3</a> often resort to materializing collections for the results of intermediate calculations, such as the result of filtering or mapping. <u>Not only can these results clutter the code [запутать код], but they also clutter the execution.[беспорядок при выполнении]</u> Materialization of intermediate collections serves only the implementation, not the result, and it consumes compute cycles organizing intermediate results into data structures that will only be discarded.</p>
<p class="cye-lm-tag">Stream pipelines, in contrast, fuse [объединять, сплавлять вместе] their operations into as few passes on the data as possible, often a single pass. (Stateful intermediate operations, such as sorting, can introduce barrier points that necessitate multipass execution.) <p>Each stage of a stream pipeline produces its elements lazily, computing elements only as needed, and feeds them directly to the next stage. You don't need a collection to hold the intermediate result of filtering or mapping, so you save the effort of populating (and garbage-collecting) the intermediate collections. </p><p>Also, following a "depth first" rather than "breadth first" execution strategy [сначала вглубину, вместо сначала вширину] (tracing the path of a single data element through the entire pipeline) causes the data being operated upon to more often be "hot" in cache, so you can spend more time computing and less time waiting for data.</p></p>
<p class="cye-lm-tag">In addition to using streams for computation, you might want to consider using streams to return aggregates from API methods, where previously you might have returned an array or collection. Returning a stream is often more efficient, since you don't have to copy all the data into a new array or collection. </p>
<p>Returning a stream is also often more flexible; the form of collection the library chooses to return might not be what the caller needs, and it's easy to convert a stream into any collection type. (The main situation in which returning a stream is inappropriate, and falling back to returning a materialized collection is better, is when the caller would need to see a consistent snapshot of the state at a point in time.)</p>

<h2 id="N10298" class="ibm-h2">Parallelism</h2>

<p class="cye-lm-tag">A beneficial consequence of structuring computations as functional transformations is that you can easily switch between sequential and parallel execution with minimal changes to the code. The sequential expression of a stream computation and the parallel expression of the same computation are almost identical. Listing 4 shows how to execute the query from <a href="#listing1">Listing 1</a> in parallel.</p>
<h5 id="listing4" class="ibm-h5">Listing 4. Parallel version of Listing 1</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_476483" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">int totalSalesFromNY</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">= txns.parallelStream()</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.filter(t -&gt; t.getSeller().getAddr().getState().equals("NY"))</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.mapToInt(t -&gt; t.getAmount())</code></div><div class="line number5 index4 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.sum();</code></div></div></td></tr></tbody></table>
</div></div></div></span><div class="ibm-pull-quote ibm-h3"><blockquote><p class="cye-lm-tag"><em class="dw-pullquote"><span class="dw-pullquote-open cye-lm-tag">“</span>Expressing a stream pipeline as a series of functional     transformations enables several useful execution strategies, such as     laziness, parallelism, short-circuiting, and operation     fusion.<span class="dw-pullquote-close cye-lm-tag">”</span></em></p>
</blockquote></div><p class="cye-lm-tag">The first line's request for a parallel stream instead of a sequential one is the only difference from <a href="#listing1">Listing 1</a>, because the Streams library effectively factors the description and structure of a computation from the strategy for executing it. Previously, going parallel entailed a complete rewrite of the code, which was not only expensive but also often error prone, because the resulting parallel code looked little like the sequential version.</p>
<p class="cye-lm-tag">All stream operations can be executed either sequentially or in parallel, but bear in mind that <b>parallelism isn't magic performance dust</b>. A parallel execution might be <u>faster than</u>, the <u>same speed</u> as, <u>or slower than</u> a sequential one. It's best to start out with sequential streams and apply parallelism when you know that you will get — and benefit from — a speedup. A later installment in this series returns to analyzing a stream pipeline for parallel performance.</p>
<h2 id="N102BB" class="ibm-h2">The fine print</h2>
<p class="cye-lm-tag">Because the Streams library is orchestrating the computation, but performing the computation involves callbacks to lambdas provided by the client, <u><b>what</b> those lambda expressions can do is subject to<b> certain contraints</b>. </u>Violating these constraints could cause the stream pipeline to fail or compute an incorrect result. Additionally, for lambdas with side effects, the timing (or existence) of these side effects might be surprising in some cases.</p>
<p class="cye-lm-tag">Most stream operations require that the lambdas passed to them be     <b><em>non-interfering</em> and <em>stateless</em>. </b>

<ul>
	<li>Non-interfering means that they won't modify the stream source; </li>
	<li>stateless means that they won't access (read or write) any state that might change during the lifetime of the stream operation. </li>
</ul>


For reduction operations (for example, computing summary data such as <code>sum</code>, <code>min</code>, or <code>max</code>) the lambdas passed to these operations must be     <em><b>associative</b></em> (or conform to similar requirements).</p>
<p class="cye-lm-tag">These requirements stem in part from the fact [Частично проистекать из факта] that the stream library might, if the pipeline executes in parallel, access the data source or invoke these lambdas concurrently from multiple threads. The restrictions are needed to ensure that the computation remains correct. (These restrictions also tend to result in more-straightforward, easier-to-understand code, regardless of parallelism.) <br><br>You might be tempted to convince yourself that you can ignore these restrictions because you don't think a particular pipeline will ever run in parallel, but it's best to resist this temptation or else you'll be burying time bombs in your code. Make the effort to express your stream pipelines such that they'll be correct regardless of execution strategy.</p>
<p class="cye-lm-tag">The root of all concurrency risks is <em>shared mutable state</em>. One possible <u>source of shared mutable state</u> is <b>the stream source</b>. If the source is a traditional collection like <code>ArrayList</code>, the Streams library assumes that it remains unmodified during the course of a stream operation. (Collections explicitly designed for concurrent access, such as <code>ConcurrentHashMap</code>, are exempt [Освобождены] from this assumption.) Not only does the noninterference requirement exclude the source being mutated by other threads during a stream operation, but the lambdas passed to stream operations themselves should also refrain from mutating the source.</p>
<p>Т.е. требование "непересекаться/не мешать" исключает возможность того, что сорс будет изменён другими потоками во время стрим операций, НО также и лямбды, переданные в стрим, будут воздерживаться от попыток изменить  сорс-стрим</p>
<p class="cye-lm-tag">In addition to not modifying the stream source, lambdas passed to stream operations should be stateless. For example, the code in Listing 5, which tries to eliminate any element that's twice some preceding element, violates this rule.</p>
<h5 id="listing5" class="ibm-h5">Listing 5. Stream pipeline using stateful lambdas (don't do     this!)</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_189239" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">HashSet&lt;</code><code class="htmlscript plain">Integer</code><code class="htmlscript plain">&gt; twiceSeen = new HashSet&lt;&gt;();</code></div><div class="line number2 index1 alt1"><code class="htmlscript plain">int[] result</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">= elements.stream()</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.filter(e -&gt; {</code></div><div class="line number5 index4 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">twiceSeen.add(e * 2);</code></div><div class="line number6 index5 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">return twiceSeen.contains(e);</code></div><div class="line number7 index6 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">})</code></div><div class="line number8 index7 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.toArray();</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">If executed in parallel, this pipeline would produce incorrect results, for two reasons. First, access to the <code>twiceSeen</code> set is done from multiple threads without any coordination and therefore isn't thread safe. Second, because the data is partitioned, there's no guarantee that when a given element is processed, all elements preceding that element were already processed. </p>
<p class="cye-lm-tag">It's best if the lambdas passed to stream operations are entirely <em><b>side     effect free</b></em> — that is, that <u>they don't mutate any heap-based state or perform any I/O during their execution</u>. If they do have side effects, it's their responsibility to provide any required coordination to ensure that such side effects are thread safe.</p>
<p class="cye-lm-tag">Further, it's not even guaranteed that all side effects will be executed. For example, in <a href="#listing6">Listing 6</a>, the library is free to avoid executing the lambda passed to <code>map()</code> entirely. Because the source has a known size, the <code>map()</code> operation is known to be size preserving, and the mapping doesn't affect the result of the computation, the <u>library can optimize the calculation by not performing the mapping at all</u>! (This optimization can turn the computation from <em>O(n)</em> to     <em>O(1)</em>, in addition to eliminating the work associated with invoking the mapping function).</p>
<h5 id="listing6" class="ibm-h5">Listing 6. Stream pipeline with side effects that might not     get executed</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_264924" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">int count = </code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">anArrayList.stream()</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.map(e -&gt; { System.out.println("Saw " + e); e })</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.count();</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">The only case in which you would notice the effect of this optimization (other than the computation being dramatically faster) is if the lambda passed to <code>map()</code> had side effects — in which case you might be surprised if those side effects don't happen. Being able to make these optimizations rests on the assumption that stream operations are functional transformations. Most of the time, we like it when the library makes our code run faster with no effort on our part. The cost of being able to make optimizations like this is that we must accept some restrictions on what the lambdas we pass to stream operations can do, and on some of our reliance on side effects. (Overall, this is a pretty good trade.)</p>
<h2 id="N10315" class="ibm-h2">Conclusion to Part 1</h2>
<p class="cye-lm-tag">The <code>java.util.stream</code> library provides a simple and flexible means to express possibly-parallel functional-style queries on various data sources, including collections, arrays, generator functions, ranges, or custom data structures. Once you start using it, you'll be hooked! The     <a href="https://www.ibm.com/developerworks/library/j-java-streams-2-brian-goetz/index.html">next installment</a> looks at one of the most powerful features of the Streams library: aggregation.</p>
<!--CMA ID: 1030930--><!--Site ID: 1--><!--XSLT stylesheet used to transform this file: dw-document-html-8.0.xsl-->                   <!-- CENTER_6_4_CONTENT_COLUMN_END -->     </div> <br><hr>  <h2>Part 2 Aggregating with Streams</h2>
 <div class="ibm-col-6-4 cye-lm-tag"> <p class="dw-article-series-head cye-lm-tag">Java Streams, Part 2</p>
         <h1 id="ibm-pagetitle-h1" class="ibm-h1 cye-lm-tag">Aggregating with Streams</h1>
<p class="dw-article-subhead cye-lm-tag">Slice, dice, and chop data with ease</p>
         <!-- Article Top Bar --> <div class="dw-article-authordate"><span class="dw-article-author cye-lm-tag"><a href="https://twitter.com/BrianGoetz">Brian Goetz</a></span><br><span class="dw-article-pubdate cye-lm-tag">Published on May 09,  2016</span><span class="dw-article-divider cye-lm-tag">/</span><span class="dw-article-updated cye-lm-tag">Updated: July 06,  2016</span></div>     </div>     <!-- Social -->     <div class="ibm-col-6-2 ibm-col-medium-6-4 ibm-col-small-6-2 dw-article-social">         <!-- Sharing links -->          </div>         </div>          <div id="dw-series-container" style="display: block;"><h3 class="ibm-h3" id="dw-series-heading">Content series:</h3>
<div data-widget="showhide" data-type="panel" class="ibm-show-hide ibm-widget-processed"><div class="ibm-container-body" id="dw-series-links" ><ul id="dw-series-list"><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-1-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 1: An introduction to the java.util.stream library</a></li><li class="dw-series-item">Part 2: Aggregating with Streams</li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-3-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 3: Streams under the hood</a></li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-4-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 4: From concurrent to parallel</a></li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-5-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 5: Parallel stream performance</a></li></ul></div></div></div>         <!-- Article Body -->                  <p class="cye-lm-tag"><a href="https://www.ibm.com/developerworks/library/j-java-streams-1-brian-goetz/index.html">Part 1</a> in the <a href="https://www.ibm.com/developerworks/views/global/libraryview.jsp?series_title_by=Java+Streams"><em>Java Streams</em></a> series introduced you to the <code>java.util.stream</code> library added in Java SE 8. This second installment focuses on one of the most important and flexible aspects of the Streams library — the ability to aggregate and summarize data. </p>
<h2 id="N1006F" class="ibm-h2">The "accumulator antipattern"</h2>
<p class="cye-lm-tag">The first example in Part 1 performed a simple summation with Streams, as shown in Listing 1.</p>
<h5 id="listing1" class="ibm-h5">Listing 1. Computing an aggregate value declaratively with     Streams</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_586272" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">int totalSalesFromNY</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">= txns.stream()</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.filter(t -&gt; t.getSeller().getAddr().getState().equals("NY"))</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.mapToInt(t -&gt; t.getAmount())</code></div><div class="line number5 index4 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.sum();</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">Listing 2 shows how this example might be written the "old way."</p>
<h5 id="listing2" class="ibm-h5">Listing 2. Computing the same aggregate value     imperatively</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_154798" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">int sum = 0;</code></div><div class="line number2 index1 alt1"><code class="htmlscript plain">for (Txn t : txns) {</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">if (t.getSeller().getAddr().getState().equals("NY"))</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">sum += t.getAmount();</code></div><div class="line number5 index4 alt2"><code class="htmlscript plain">}</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">Part 1 offers several reasons why the new way is preferable, despite being longer than the old way:</p>
<ul class="ibm-bullet-list"><li>The code is clearer because it is cleanly factored into the     composition of simple operations.</li><li>The code is expressed declaratively (describing the desired result)     rather than imperatively (a step-by-step procedure for how to compute     the result).</li><li>This approach scales more cleanly as the query being expressed gets     more complicated.</li></ul><p class="cye-lm-tag">Some additional reasons apply to the particular case of aggregation. <a href="#listing2">Listing 2</a> is an illustration of the     <em>accumulator antipattern</em>, where the code starts out declaring and initializing a mutable accumulator variable (<code>sum</code>) and then proceeds to update the accumulator in a loop. Why is this bad? First, this style of code is difficult to parallelize. Without coordination (such as synchronization), every access to the accumulator would be a data race (and with coordination, the contention resulting from coordination would more than undermine the efficiency gain available from parallelism).</p>
<p class="cye-lm-tag">Another reason why the accumulator approach is less desirable is that it models the computation at too low a level — at the level of individual elements, rather than on the data set as a whole. "The sum of all the transaction amounts" is a more abstract and direct statement of the goal than "Iterate through the transaction amounts one by one in order, adding each amount to an accumulator that has been previously initialized to zero."</p>
<p class="cye-lm-tag">So, if imperative accumulation is the wrong tool, what's the right one? In this specific problem, you've seen a hint of the answer — the <code>sum()</code> method — but this is merely a special case of a powerful and general technique, <em>reduction</em>. Reduction is simple, flexible, and parallelizable, and operates at a higher level of abstraction than imperative accumulation.</p>
<h2 id="N100CC" class="ibm-h2">Reduction (aka Folding)</h2>
<p>Reduction -- сокращение, уменьшение, -- the action or fact of making a specified thing smaller or less in amount, degree, or size.</p>
<div class="ibm-pull-quote ibm-h3"><blockquote><p class="cye-lm-tag"><em class="dw-pullquote"><span class="dw-pullquote-open cye-lm-tag">“</span>Reduction is simple, flexible, and parallelizable, and     operates at a higher level of abstraction than imperative     accumulation.<span class="dw-pullquote-close cye-lm-tag">”</span></em></p>
</blockquote></div><p class="cye-lm-tag">Reduction (also known as <em>folding</em>) is a technique from functional programming that abstracts over many different accumulation operations. Given a nonempty sequence X of elements x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub> of type T and a binary operator on T (represented here by *), the <em>reduction</em> of X under * is defined as:</p>
<blockquote><em>&nbsp;&nbsp;&nbsp;(x<sub>1</sub> * x<sub>2</sub> * ... *     x<sub>n</sub>)</em></blockquote><p class="cye-lm-tag">&nbsp;</p>
<p class="cye-lm-tag">When applied to a sequence of numbers using ordinary addition as the binary operator, reduction is simply summation. But many other operations can be described by reduction. If the binary operator is "take the larger of the two elements" (which could be represented in Java by the lambda expression <code>(x,y) -&gt; Math.max(x,y)</code>, or more simply as the method reference <code>Math::max</code>), reduction corresponds to finding the maximal value.</p>
<p class="cye-lm-tag">By describing an accumulation as a reduction instead of with the accumulator antipattern, you describe the computation in a more     <strong>abstract</strong> and <strong>compact</strong> way, as well as a more <strong>parallel-friendly</strong> way — provided your binary operator satisfies a simple condition: <em>associativity</em>. Recall that a binary operator * is <em>associative</em> if, for any elements a, b, and c:</p>
<blockquote><em>&nbsp;&nbsp;&nbsp;((a * b) * c) = (a * (b * c))</em></blockquote><p class="cye-lm-tag">&nbsp;</p>
<p class="cye-lm-tag"><b>Associativity</b> means that <strong><u>grouping doesn't matter</u></strong>. If the binary operator is associative, the reduction can be safely performed in any order. In a sequential execution, the natural order of execution is from left to right; in a parallel execution, the data is partitioned into segments, reduce each segment separately, and combine the results. Associativity ensures that these two approaches yield the same answer. This is easier to see if the definition of associativity is expanded to four terms:</p>
<blockquote><em>&nbsp;&nbsp;&nbsp;(((a * b) * c) * d) = ((a * b) * (c *     d))</em></blockquote><p class="cye-lm-tag">&nbsp;</p>
<p class="cye-lm-tag">The left side corresponds to a typical sequential computation; the right side corresponds to a partitioned execution that would be typical of a parallel execution where the input sequence is broken into parts, the parts reduced in parallel, and the partial results combined with *. (Perhaps surprisingly, * need not be commutative, [<u>т.е. результат умножения может зависеть от перестановки переменных</u>] though many operators commonly used for reduction, such as as plus and max, are [commutative]. An example of a binary operator that's associative but not commutative is string concatenation.) [т.е. группировка при конкатенации пофиг, а вот перестановка стрингов повляет на результат] </p>
<ul>
	<li><b>commutative</b> -- <b>перестановка</b> <u>переменных не важна</u>, результат должен остаться одинаковым.</li>
	<li><b>associative</b> -- <b>порядок</b> <u>операций не важен</u>. Т.е. можно по-разному расставить скобочки, чтобы порядок операций был разный, результат должен остаться одинаковым.</li>
	<li> <b>Distributive</b> -- <u>различная</u> <b>группировка</b> <u>операций должна приводить к одинаковому результату</u></li>
</ul>
<p>
	<table width="100%" border="0" cellpadding="6">
				<tbody><tr>
					<td valign="top" class="larger">Commutative Laws:<br>
<span class="large cye-lm-tag">a + b<b> &nbsp;=&nbsp; </b>b + a<br>
						a × b<b> &nbsp;=&nbsp; </b>b × a</span>
					</td>
					<td>
							<img src="pics/commutative-add.gif">
					</td>
						<td>
							<img src="pics/commutative-multiply.gif">
						</td>
				</tr>
				<tr>
					<td valign="top" class="larger">Associative Laws:<br>
					<span class="large cye-lm-tag">(a + b) + c<b> &nbsp;=&nbsp; </b>a + (b + c)<br>
						(a × b) × c<b> &nbsp;=&nbsp; </b>a × (b × c)</span>
					</td>
					<td>
							<img src="pics/associative-add.gif">
						</td>
						<td>
							<img src="pics/associative-multiply.gif">
						</td>
				</tr>
				<tr>
					<td valign="top" class="larger">Distributive Law:</td>
					<td class="large">
					<b>a × (b + c)   &nbsp;=&nbsp; a × b &nbsp;+&nbsp; a × c</b>
					</td>
					<td>
							<img src="pics/distributive-law.gif">
						</td>
				</tr>
			</tbody></table>
</p>
<p class="cye-lm-tag">The Streams library has several methods for reduction, including:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_508008" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">Optional&lt;</code><code class="htmlscript plain">T</code><code class="htmlscript plain">&gt; reduce(BinaryOperator&lt;</code><code class="htmlscript plain">T</code><code class="htmlscript plain">&gt; op)</code></div><div class="line number2 index1 alt1"><code class="htmlscript plain">T reduce(T identity, BinaryOperator&lt;</code><code class="htmlscript plain">T</code><code class="htmlscript plain">&gt; op)</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">The simpler of these methods takes only an <b>associative binary operator</b> [оператор, в котором группировка переменных не важна] and computes the reduction of the stream elements under that operator. The result is described as an <code><b>Optional</b></code>; if the input stream is empty, the result of reduction is also empty. (If the input has only a single element, the result of the reduction is that element.) If you had a collection of strings, you could compute the concatenation of the elements as:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_773889" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">String concatenated = strings.stream().reduce("", String::concat);</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">With the second of the two method forms, you provide an <b>identity value</b>, which is also used <b>as the result if the stream is empty</b>. <br>The <b>identity value</b> <u>must satisfy the constraints</u> that for all <em>x</em>:</p>
<blockquote><em>&nbsp;&nbsp;&nbsp;<b>identity * x =     x<br>&nbsp;&nbsp;&nbsp;x * identity = x</b></em></blockquote>
<p class="cye-lm-tag">Not all binary operators have identity values, and when they do, they might not yield the results that you're looking for [Они могут не дать результатов, которые вы ищете] . For example, when computing maxima, you might be tempted to use the value <code>Integer.MIN_VALUE</code> as your identity (it does satisfy the requirements). But the result <u>when that identity is used on an empty stream might not be what you want</u>; you wouldn't be able to tell the difference between an empty input and a nonempty input containing only <code>Integer.MIN_VALUE</code>. (Sometimes that's not a problem, and sometimes it is — which is why the Streams library leaves it to the client to specify, or not specify, an identity.)</p>
<p class="cye-lm-tag">For string concatenation, the identity is the empty string, so you could recast the previous example as:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_143440" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">String concatenated = strings.stream().reduce("", String::concat);</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">Similarly, you could describe integer summation over an array as:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_629387" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">int sum = Stream.of(ints).reduce(0, (x,y) -&gt; x+y);</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">(In practice, though, you'd use the <code>IntStream.sum()</code> convenience method.)</p>
<p class="cye-lm-tag">Reduction needn't apply only to integers and strings; it can be applied in any situation where you want to reduce a sequence of elements down to a single element of that type. For example, you can<u> compute the tallest person via reduction</u>:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_878323" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">Comparator&lt;</code><code class="htmlscript plain">Person</code><code class="htmlscript plain">&gt; byHeight = Comparators.comparingInt(Person::getHeight);</code></div><div class="line number2 index1 alt1"><code class="htmlscript plain">BinaryOperator&lt;</code><code class="htmlscript plain">Person</code><code class="htmlscript plain">&gt; tallerOf = BinaryOperator.maxBy(byHeight);</code></div><div class="line number3 index2 alt2"><code class="htmlscript plain">Optional&lt;</code><code class="htmlscript plain">Person</code><code class="htmlscript plain">&gt; tallest = people.stream().reduce(tallerOf);</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">If the provided<b> binary operator isn't associative</b>, or the provided <b>identity value isn't actually an identity</b> for the binary operator, then<u> when the operation is executed in parallel</u>, the <b>result might be incorrect</b>, and <u>different executions on the same data set might produce different results</u>.</p>

<h2 id="N10172" class="ibm-h2">Mutable reduction</h2>

<p><b>Reduction takes a sequence of values and reduces it to a single value, such as the sequence's sum or its maximal value.</b></p>
<p class="cye-lm-tag"> But sometimes you don't want a single summary value; instead, you want to organize the results into a data structure like a <code>List</code> or <code>Map</code>, or reduce it to more than one summary value. In that case, you should use the mutable analogue of <code><b>reduce</b></code>, called <code><B>collect</B></code>.</p>
<p class="cye-lm-tag">Consider the simple case of accumulating elements into a <code>List</code>. Using the accumulator antipattern, you might write it this way:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_402302" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">ArrayList&lt;</code><code class="htmlscript plain">String</code><code class="htmlscript plain">&gt; list = new ArrayList&lt;&gt;();</code></div><div class="line number2 index1 alt1"><code class="htmlscript plain">for (Person p : people)</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">list.add(p.toString());</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">Just as <b>reduction is a better alternative to accumulation when the accumulator variable is a simple value</b>, there's also a better alternative <b>when the accumulator result is a more complex data structure</b>. The building blocks of reduction are an <u>(1) identity value</u> and <u>(2) a means of combining two values into a new value</u>; <br>the analogues for mutable reduction are:</p>
<ul class="ibm-bullet-list"><li>A means of producing an empty result container</li><li>A means of incorporating a new element into a result container</li><li>A means of merging two result containers</li></ul><p class="cye-lm-tag">These building blocks can be easily expressed as functions. The third of these functions enables mutable reduction to occur in parallel: You can partition the data set, produce an intermediate accumulation for each section, and then merge the intermediate results. The Streams library has a <code>collect()</code> method that takes these three functions:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_662917" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">&lt;</code><code class="htmlscript plain">R</code><code class="htmlscript plain">&gt; collect(Supplier&lt;</code><code class="htmlscript plain">R</code><code class="htmlscript plain">&gt; resultSupplier,</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">BiConsumer&lt;</code><code class="htmlscript plain">R</code><code class="htmlscript plain">, T&gt; accumulator, </code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">BiConsumer&lt;</code><code class="htmlscript plain">R</code><code class="htmlscript plain">, R&gt; combiner)</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">In the preceding section, you saw an example of using reduction to compute string concatenation. That idiom produces the correct result, but — because strings are immutable in Java and concatenation entails copying the whole string — it will have <em>O(n<sup>2</sup>)</em> runtime (some strings will be copied many times). You can express string concatenation more efficiently by collecting into a <code>StringBuilder</code>:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_519013" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">StringBuilder concat = strings.stream()</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.collect(() -&gt; new StringBuilder(),</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">(sb, s) -&gt; sb.append(s),</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">(sb, sb2) -&gt; sb.append(sb2));</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">This approach uses a <code>StringBuilder</code> as the result container. The three functions passed to <code>collect()</code> use the default constructor to create an empty container, the <code>append(String)</code> method to add an element to the container, and the <code>append(StringBuilder)</code> method to merge one container into another. This code is probably better expressed using method references rather than lambdas:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_49643" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">StringBuilder concat = strings.stream()</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.collect(StringBuilder::new,</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">StringBuilder::append,</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">StringBuilder::append);</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">Similarly, to collect a stream into a <code>HashSet</code>, you could do this:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_43607" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">Set&lt;</code><code class="htmlscript plain">String</code><code class="htmlscript plain">&gt; uniqueStrings = strings.stream()</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.collect(HashSet::new,</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">HashSet::add,</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">HashSet::addAll);</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">In this version, the result container is a <code>HashSet</code> rather than a <code>StringBuilder</code>, but the approach is the same: Use the default constructor to create a new result container, the <code>add()</code> method to incorporate a new element to the set, and the <code>addAll()</code> method to merge two sets. It's easy to see how to adapt this code to any other sort of collection.</p>
<p class="cye-lm-tag">You might think, because a mutable result container (a <code>StringBuilder</code> or <code>HashSet</code>) is being used, that this is also an example of the accumulator antipattern. However, that's not the case. The analogue of the accumulator antipattern in this case would be:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_883191" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">Set&lt;</code><code class="htmlscript plain">String</code><code class="htmlscript plain">&gt; set = new HashSet&lt;&gt;();</code></div><div class="line number2 index1 alt1"><code class="htmlscript plain">strings.stream().forEach(s -&gt; set.add(s));</code></div></div></td></tr></tbody></table>
</div></div></div></span><div class="ibm-pull-quote ibm-h3"><blockquote><p class="cye-lm-tag"><em class="dw-pullquote"><span class="dw-pullquote-open cye-lm-tag">“</span>Collectors can be composed together to perform more     complex aggregations.<span class="dw-pullquote-close cye-lm-tag">”</span></em></p>
</blockquote></div><p class="cye-lm-tag">Just as [reduction can parallelize safely] [provided the combining function is associative and free of interfering side effects]. <br>Mutable reduction with <code>Stream.collect()</code> can parallelize safely if it meets certain simple consistency requirements (outlined in the specification for <code>collect()</code>). The <b>key difference</b> is that, with the <code><u>forEach()</u></code> version, <u>multiple threads are trying to access a single result container simultaneously</u>, whereas with parallel <code><u>collect()</u></code>, <u>each thread has its own local result container</u>, the results of which are merged afterward. </p>
<h2 id="N10200" class="ibm-h2">Collectors</h2>
<p class="cye-lm-tag">The relationship among the three functions passed to <code>collect()</code>— creating, populating, and merging result containers — is important enough to be given its own abstraction, <code>Collector</code>, along with a corresponding simplified version of <code>collect()</code>. The string-concatenation example can be rewritten as:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_872804" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">String concat = strings.stream().collect(Collectors.joining());</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">And the collect-to-set example can be rewritten as:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_594095" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">Set&lt;</code><code class="htmlscript plain">String</code><code class="htmlscript plain">&gt; uniqueStrings = strings.stream().collect(Collectors.toSet());</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">The <code>Collectors</code> class contains factories for many common aggregation operations, such as accumulation to collections, string concatenation, reduction and other summary computation, and the creation of summary tables (via <code>groupingBy()</code>). Table 1 contains a partial list of built-in collectors, and if these aren't sufficient, it's easy to write your own (see the "<a href="#cc">Custom collectors</a>" section).</p>
<h5 id="table1" class="ibm-h5">Table 1. Built-in collectors</h5>
<table border="0" cellpadding="0" cellspacing="0" class="ibm-data-table"><thead xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><tr><th scope="col">Collector</th><th scope="col">Behavior</th></tr></thead><tbody xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><tr><td><code>toList()</code></td><td> Collect the elements to a <code>List</code>.</td></tr><tr><td><code>toSet()</code></td><td> Collect the elements to a <code>Set</code>.</td></tr><tr><td><code>toCollection(Supplier&lt;Collection&gt;)</code></td><td> Collect the elements to a specific kind of <code>Collection</code>.</td></tr><tr><td><code>toMap(Function&lt;T, K&gt;, Function&lt;T, V&gt;)</code></td><td> Collect the elements to a <code>Map</code>, transforming the elements into keys and values according to the provided mapping functions.</td></tr><tr><td><code>summingInt(ToIntFunction&lt;T&gt;)</code></td><td> Compute the sum of applying the provided <code>int</code>-valued mapping function to each element (also versions for <code>long</code> and         <code>double</code>).</td></tr><tr><td><code>summarizingInt(ToIntFunction&lt;T&gt;)</code></td><td> Compute the <code>sum</code>, <code>min</code>, <code>max</code>, <code>count</code>, and <code>average</code> of the results of applying the provided <code>int</code>-valued mapping function to each element (also versions for <code>long</code> and         <code>double</code>).</td></tr><tr><td><code>reducing()</code></td><td> Apply a reduction to the elements (usually used as a downstream collector, such as with <code>groupingBy</code>) (various versions). </td></tr><tr><td><code>partitioningBy(Predicate&lt;T&gt;)</code></td><td> Divide the elements into two groups: those for which the supplied predicate holds and those for which it         doesn't.</td></tr><tr><td><code>partitioningBy(Predicate&lt;T&gt;, Collector)</code></td><td> Partition the elements, and process each partition with the specified downstream collector.</td></tr><tr><td><code>groupingBy(Function&lt;T,U&gt;)</code></td><td> Group elements into a <code>Map</code> whose keys are the provided function applied to the elements of the stream, and whose values are lists of elements that share that key.</td></tr><tr><td><code>groupingBy(Function&lt;T,U&gt;, Collector)</code></td><td> Group the elements, and process the values associated with each group with the specified downstream collector.</td></tr><tr><td><code>minBy(BinaryOperator&lt;T&gt;)</code></td><td> Compute the minimal value of the elements (also <code>maxBy()</code>).</td></tr><tr><td><code>mapping(Function&lt;T,U&gt;, Collector)</code></td><td> Apply the provided mapping function to each element, and process with the specified downstream collector (usually used as a downstream collector itself, such as with <code>groupingBy</code>).</td></tr><tr><td><code>joining()</code></td><td> Assuming elements of type <code>String</code>, join the elements into a string, possibly with a delimiter, prefix, and suffix.</td></tr><tr><td><code>counting()</code></td><td> Compute the count of elements. (Usually used as a downstream collector.)</td></tr></tbody></table>
<p class="cye-lm-tag">Grouping the collector functions together into the <code>Collector</code> abstraction is syntactically simpler, but the real benefit comes from when you start to compose collectors together — such as when you want to create complex summaries such as those created by the <code>groupingBy()</code> collector, which collects elements into a <code>Map</code> according to a key derived from the element. For example, to create a <code>Map</code> of transactions over $1,000, keyed by seller:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_726673" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">Map&lt;</code><code class="htmlscript plain">Seller</code><code class="htmlscript plain">, List&lt;Txn&gt;&gt; bigTxnsBySeller =</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">txns.stream()</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.filter(t -&gt; t.getAmount() &gt; 1000)</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.collect(groupingBy(Txn::getSeller));</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">Suppose, though, that you don't want a <code>List</code> of transactions for each seller, but instead the largest transaction from each seller. You still want to key the result by seller, but you want to do further processing of the transactions associated with that seller, to reduce it down to the largest transaction. You can use an alternative version of <code>groupingBy()</code> that, rather than collecting the elements for each key into a list, feeds them to another collector (the     <em>downstream</em> collector). For your downstream collector, you can choose a reduction such as <code>maxBy()</code>:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_167292" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">Map&lt;</code><code class="htmlscript plain">Seller</code><code class="htmlscript plain">, Txn&gt; biggestTxnBySeller =</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">txns.stream()</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.collect(groupingBy(Txn::getSeller,</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">maxBy(comparing(Txn::getAmount))));</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">Here, you group the transactions into a map keyed by seller, but the value of that map is the result of using the <code>maxBy()</code> collector to collect all the sales by that seller. If you want not the largest transaction by seller, but the sum, you could use the <code>summingInt()</code> collector:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_297919" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">Map&lt;</code><code class="htmlscript plain">Seller</code><code class="htmlscript plain">, Integer&gt; salesBySeller =</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">txns.stream()</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.collect(groupingBy(Txn::getSeller,</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">summingInt(Txn::getAmount)));</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">To get a multilevel summary, such as sales by region and seller, you can simply use another <code>groupingBy</code> collector as the downstream collector: </p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_809243" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">Map&lt;</code><code class="htmlscript plain">Region</code><code class="htmlscript plain">, Map&lt;Seller, Integer&gt;&gt; salesByRegionAndSeller =</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">txns.stream()</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.collect(groupingBy(Txn::getRegion,</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">groupingBy(Txn::getSeller, </code></div><div class="line number5 index4 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">summingInt(Txn::getAmount))));</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">To pick an example from a different domain: To compute a histogram of word frequencies in a document, you can split the document into lines with <code>BufferedReader.lines()</code>, break it up into a stream of words by using <code>Pattern.splitAsStream()</code>, and then use <code>collect()</code> and <code>groupingBy()</code> to create a <code>Map</code> whose keys are words and whose values are counts of those words, as shown in Listing 3.</p>
<h5 id="listing3" class="ibm-h5">Listing 3. Computing a word-count histogram with Streams</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_168032" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">Pattern whitespace = Pattern.compile("\\s+");</code></div><div class="line number2 index1 alt1"><code class="htmlscript plain">Map&lt;</code><code class="htmlscript plain">String</code><code class="htmlscript plain">, Integer&gt; wordFrequencies =</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">reader.lines()</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.flatMap(s -&gt; whitespace.splitAsStream())</code></div><div class="line number5 index4 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.collect(groupingBy(String::toLowerCase),</code></div><div class="line number6 index5 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">Collectors.counting());</code></div></div></td></tr></tbody></table>
</div></div></div></span><h2 id="cc" class="ibm-h2">Custom collectors</h2>
<p class="cye-lm-tag">While the standard set of collectors provided by the JDK is fairly rich, it's also easy to write your own collector. The <code>Collector</code> interface, shown in Listing 4, is fairly simple. The interface is parameterized by three types — the input type <code>T</code>, the accumulator type <code>A</code>, and the final return type <code>R</code> (<code>A</code> and <code>R</code> are often the same) — and the methods return functions that look similar to the functions accepted by the three-argument version of <code>collect()</code> illustrated earlier. </p>
<h5 id="listing4" class="ibm-h5">Listing 4. The     <code>Collector</code> interface</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_281701" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">public interface Collector&lt;</code><code class="htmlscript plain">T</code><code class="htmlscript plain">, A, R&gt; {</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">/** Return a function that creates a new empty result container */</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">Supplier&lt;</code><code class="htmlscript plain">A</code><code class="htmlscript plain">&gt; supplier();</code></div><div class="line number4 index3 alt1">&nbsp;</div><div class="line number5 index4 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">/** Return a function that incorporates an element into a container */</code></div><div class="line number6 index5 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">BiConsumer&lt;</code><code class="htmlscript plain">A</code><code class="htmlscript plain">, T&gt; accumulator();</code></div><div class="line number7 index6 alt2">&nbsp;</div><div class="line number8 index7 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">/** Return a function that merges two result containers */</code></div><div class="line number9 index8 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">BinaryOperator&lt;</code><code class="htmlscript plain">A</code><code class="htmlscript plain">&gt; combiner();</code></div><div class="line number10 index9 alt1">&nbsp;</div><div class="line number11 index10 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">/** Return a function that converts the intermediate result container</code></div><div class="line number12 index11 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">into the final representation */</code></div><div class="line number13 index12 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">Function&lt;</code><code class="htmlscript plain">A</code><code class="htmlscript plain">, R&gt; finisher();</code></div><div class="line number14 index13 alt1">&nbsp;</div><div class="line number15 index14 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">/** Special characteristics of this collector */</code></div><div class="line number16 index15 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">Set&lt;</code><code class="htmlscript plain">Characteristics</code><code class="htmlscript plain">&gt; characteristics();</code></div><div class="line number17 index16 alt2"><code class="htmlscript plain">}</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">The implementation of most of the collector factories in <code>Collectors</code> is trivial. For example, the implementation of <code>toList()</code> is:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_906230" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">return new CollectorImpl&lt;&gt;(ArrayList::new,</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">List::add,</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">(left, right) -&gt; { left.addAll(right); return left; },</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">CH_ID);</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">This implementation uses <code>ArrayList</code> as the result container, <code>add()</code> to incorporate an element, and <code>addAll()</code> to merge one list into another, indicating through the characteristics that its finish function is the identity function (which enables the stream framework to optimize the execution).</p>
<p class="cye-lm-tag">As you've seen before, there are some consistency requirements that are analogous to the constraints between the identity and the accumulator function in reduction. These requirements are outlined in the specification for <code>Collector</code>.</p>
<<<<<<< HEAD

<div style="border: 1px solid #920000">
<span>from Collector's javadoc:</span><br>
	To ensure that sequential and parallel executions produce equivalent results, the collector functions must satisfy an identity and an associativity constraints.

<p>The identity constraint says that for any partially accumulated result, combining it with an empty result container must produce an equivalent result. That is, for a partially accumulated result a that is the result of any series of accumulator and combiner invocations, a must be equivalent to combiner.apply(a, supplier.get()).</p>

The associativity constraint says that splitting the computation must produce an equivalent result. That is, for any input elements t1 and t2, the results r1 and r2 in the computation below must be equivalent:
   

<pre>
      A a1 = supplier.get();
      accumulator.accept(a1, t1);
      accumulator.accept(a1, t2);
      R r1 = finisher.apply(a1);  // result without splitting
 
      A a2 = supplier.get();
      accumulator.accept(a2, t1);
      A a3 = supplier.get();
      accumulator.accept(a3, t2);
      R r2 = finisher.apply(combiner.apply(a2, a3));  // result with splitting

</pre>
</div>

=======
>>>>>>> f8a536c4678db8b83ae8e727ec6020ad23c553ef
<p class="cye-lm-tag">As a more complex example, consider the problem of creating summary statistics on a data set. It's easy to use reduction to compute the sum, minimum, maximum, or count of a numeric data set (and you can compute average from sum and count). Its harder to compute them all at once, in a single pass on the data, using reduction. But you can easily write a <code>Collector</code> to do this computation efficiently (and in parallel, if you like).</p>
<p class="cye-lm-tag">The <code>Collectors</code> class contains a <code>collectingInt()</code> factory method that returns an <code>IntSummaryStatistics</code>, which does exactly what you want — compute <code>sum</code>, <code>min</code>, <code>max</code>, <code>count</code>, and <code>average</code> in one pass. The implementation of <code>IntSummaryStatistics</code> is trivial, and you can easily write your own similar collectors to compute arbitrary data summaries (or extend this one).</p>
<p class="cye-lm-tag">Listing 5 shows the <code>IntSummaryStatistics</code> class. The actual implementation has more detail (including getters to return the summary statistics), but the heart of it is the simple <code>accept()</code> and <code>combine()</code> methods.</p>
<h5 id="listing5" class="ibm-h5">Listing 5. The     <code>IntSummaryStatistics</code> class used by the     <code>summarizingInt()</code> collector</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_78730" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">public class IntSummaryStatistics implements IntConsumer {</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">private long count;</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">private long sum;</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">private int min = Integer.MAX_VALUE;</code></div><div class="line number5 index4 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">private int max = Integer.MIN_VALUE;</code></div><div class="line number6 index5 alt1">&nbsp;</div><div class="line number7 index6 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">public void accept(int value) {</code></div><div class="line number8 index7 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">++count;</code></div><div class="line number9 index8 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">sum += value;</code></div><div class="line number10 index9 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">min = Math.min(min, value);</code></div><div class="line number11 index10 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">max = Math.max(max, value);</code></div><div class="line number12 index11 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">}</code></div><div class="line number13 index12 alt2">&nbsp;</div><div class="line number14 index13 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">public void combine(IntSummaryStatistics other) {</code></div><div class="line number15 index14 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">count += other.count;</code></div><div class="line number16 index15 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">sum += other.sum;</code></div><div class="line number17 index16 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">min = Math.min(min, other.min);</code></div><div class="line number18 index17 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">max = Math.max(max, other.max);</code></div><div class="line number19 index18 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">}</code></div><div class="line number20 index19 alt1">&nbsp;</div><div class="line number21 index20 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">// plus getters for count, sum, min, max, and average</code></div><div class="line number22 index21 alt1"><code class="htmlscript plain">}</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">As you can see, this is a pretty simple class. As each new data element is observed, the various summaries are updated in the obvious way, and two <code>IntSummaryStatistics</code> holders are combined in the obvious way. The implementation of <code>Collectors.summarizingInt()</code>, shown in Listing 6, is similarly simple; it creates a <code>Collector</code> that incorporates an element by applying an integer-valued extractor function and passing the result to <code>IntSummaryStatistics.accept()</code>.</p>
<h5 id="listing6" class="ibm-h5">Listing 6. The     <code>summarizingInt()</code> collector factory</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_386694" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">public static &lt;</code><code class="htmlscript plain">T</code><code class="htmlscript plain">&gt;</code></div><div class="line number2 index1 alt1"><code class="htmlscript plain">Collector&lt;</code><code class="htmlscript plain">T</code><code class="htmlscript plain">, ?, IntSummaryStatistics&gt; summarizingInt(ToIntFunction&lt;? </code><code class="htmlscript plain">super</code> <code class="htmlscript plain">T&gt; mapper) {</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">return new CollectorImpl&lt;</code><code class="htmlscript plain">T</code><code class="htmlscript plain">, IntSummaryStatistics, IntSummaryStatistics&gt;(</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">IntSummaryStatistics::new,</code></div><div class="line number5 index4 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">(r, t) -&gt; r.accept(mapper.applyAsInt(t)),</code></div><div class="line number6 index5 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">(l, r) -&gt; { l.combine(r); return l; },</code></div><div class="line number7 index6 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">CH_ID);</code></div><div class="line number8 index7 alt1"><code class="htmlscript plain">}</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">The ease of composing collectors (which you saw with the <code>groupingBy()</code> examples) and the ease of creating new collectors combine to make it possible to compute almost arbitrary summaries of stream data while keeping your code compact and clear. </p>
<h2 id="N103D2" class="ibm-h2">Conclusion to Part 2</h2>
<p class="cye-lm-tag">The facilities for aggregation are one of the most useful and flexible parts of the Streams library. Simple values can be easily aggregated, sequentially or in parallel, using reduction; more complex summaries can created via <code>collect()</code>. The library ships with a simple set of basic collectors that can be composed together to perform more complex aggregations, and you can easily add your own collectors to the mix.</p>
<p class="cye-lm-tag">In <a href="https://www.ibm.com/developerworks/library/j-java-streams-3-brian-goetz/index.html">Part 3</a>, dig into the internals of Streams to understand how to use the library most efficiently when performance is critical.</p>
<!--CMA ID: 1030938--><!--Site ID: 1--><!--XSLT stylesheet used to transform this file: dw-document-html-8.0.xsl-->                   <!-- CENTER_6_4_CONTENT_COLUMN_END -->     </div> <br><hr>  <h2>Part 3 Streams under the hood</h2>
 <div class="ibm-col-6-4 cye-lm-tag"> <p class="dw-article-series-head cye-lm-tag">Java Streams, Part 3</p>
         <h1 id="ibm-pagetitle-h1" class="ibm-h1">Streams under the hood</h1>
<p class="dw-article-subhead cye-lm-tag">Understand java.util.stream internals </p>
         <!-- Article Top Bar --> <div class="dw-article-authordate"><span class="dw-article-author cye-lm-tag"><a href="https://twitter.com/BrianGoetz">Brian Goetz</a></span><br><span class="dw-article-pubdate cye-lm-tag">Published on May 09,  2016</span><span class="dw-article-divider cye-lm-tag">/</span><span class="dw-article-updated cye-lm-tag">Updated: July 06,  2016</span></div>     </div>     <!-- Social -->     <div class="ibm-col-6-2 ibm-col-medium-6-4 ibm-col-small-6-2 dw-article-social">         <!-- Sharing links -->          </div>         </div>          <div id="dw-series-container" style="display: block;"><h3 class="ibm-h3" id="dw-series-heading">Content series:</h3>
<div data-widget="showhide" data-type="panel" class="ibm-show-hide ibm-widget-processed"><div class="ibm-container-body" id="dw-series-links" ><ul id="dw-series-list"><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-1-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 1: An introduction to the java.util.stream library</a></li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-2-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 2: Aggregating with Streams</a></li><li class="dw-series-item">Part 3: Streams under the hood</li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-4-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 4: From concurrent to parallel</a></li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-5-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 5: Parallel stream performance</a></li></ul></div></div></div>         <!-- Article Body -->                  <p class="cye-lm-tag">The first two articles in <a href="http://www.ibm.com/developerworks/library/?search_by=Java+Streams,+Part" class="cye-lm-tag">this series</a> explore how to use the <code>java.util.stream</code> library added in Java SE 8, which makes it easy to express a query on a data set declaratively. In many cases, the library figures out how to perform queries efficiently, with no help from the user. But when performance is critical, it's valuable to understand how the library works internally, so that you can eliminate possible sources of inefficiency. This third installment explores how the implementation of Streams works and explains some of the optimizations that the declarative approach makes possible.</p>
<h2 id="N10066" class="ibm-h2">Stream pipelines</h2>
<p class="cye-lm-tag">A <em>stream pipeline</em> is composed of a <em>stream source</em>, zero or more <em>intermediate operations</em>, and a <em>terminal operation</em>. Stream sources can be collections, arrays, generator functions, or any other data source that can suitably provide access to its elements. Intermediate operations transform streams into other streams — by filtering the elements (<code>filter()</code>), transforming the elements (<code>map()</code>), sorting the elements (<code>sorted()</code>), truncating the stream to a certain size (<code>limit()</code>), and so on. Terminal operations include aggregations (<code>reduce()</code>, <code>collect()</code>), searching (<code>findFirst()</code>), and iteration (<code>forEach()</code>).</p>
<p class="cye-lm-tag">Stream pipelines are constructed lazily. Constructing a stream source doesn't compute the elements of the stream, but instead captures how to find the elements when necessary. Similarly, invoking an intermediate operation doesn't perform any computation on the elements; it merely adds another operation to the end of the stream description. Only when the terminal operation is invoked does the pipeline actually perform the work — compute the elements, apply the intermediate operations, and apply the terminal operation. This approach to execution makes several interesting optimizations possible.</p>
<h2 id="N100A4" class="ibm-h2">Stream sources</h2>
<p class="cye-lm-tag">A stream source is described by an abstraction called <code>Spliterator</code>. As its name suggests, <code>Spliterator</code> combines two behaviors: accessing the elements of the source (iterating), and possibly decomposing the input source for parallel execution (splitting).</p>
<p class="cye-lm-tag">Although <code>Spliterator</code> includes the same basic behaviors as <code>Iterator</code>, it doesn't extend <code>Iterator</code>, instead taking a different approach to element access. An <code>Iterator</code> has two methods, <code>hasNext()</code> and <code>next()</code>; accessing the next element can involve (but doesn't require) calling both of these methods. As a result, coding an <code>Iterator</code> correctly requires a certain amount of defensive and duplicative coding. (What if the client doesn't call <code>hasNext()</code> before <code>next()</code>? What if it calls <code>hasNext()</code> twice?) Additionally, the two-method protocol generally requires a fair amount of statefulness, such as peeking ahead one element (and keeping track of whether you've already peeked ahead). Together, these requirements add up to a fair degree of per-element access overhead.</p>
<p class="cye-lm-tag">Having lambdas in the language enables <code>Spliterator</code> to take an approach to element access that's generally more efficient — and easier to code correctly. <code>Spliterator</code> has two methods for accessing elements:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_884994" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">boolean tryAdvance(Consumer&lt;? </code><code class="htmlscript plain">super</code> <code class="htmlscript plain">T&gt; action);</code></div><div class="line number2 index1 alt1"><code class="htmlscript plain">void forEachRemaining(Consumer&lt;? </code><code class="htmlscript plain">super</code> <code class="htmlscript plain">T&gt; action);</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">The <code>tryAdvance()</code> method tries to process a single element. If no elements remain, <code>tryAdvance()</code> merely returns <code>false</code>; otherwise, it advances the cursor and passes the current element to the provided handler and returns <code>true</code>. The <code>forEachRemaining()</code> method processes all the remaining elements, passing them one at a time to the provided handler.</p>
<p class="cye-lm-tag">Even ignoring the possibility of parallel decomposition, the <code>Spliterator</code> abstraction is already a "better iterator" — simpler to write, simpler to use, and generally having lower per-element access overhead. But the <code>Spliterator</code> abstraction also extends to parallel decomposition. A spliterator describes a sequence of remaining elements; calling the <code>tryAdvance()</code> or <code>forEachRemaining()</code> element-access method advances through that sequence. To split the source, so that two threads can work separately on different sections of the input, <code>Spliterator</code> provides a <code>trySplit()</code> method:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_669390" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">Spliterator&lt;</code><code class="htmlscript plain">T</code><code class="htmlscript plain">&gt; trySplit();</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">The behavior of <code>trySplit()</code> is to try to split the remaining elements into two sections, ideally of similar size. If the <code>Spliterator</code> can be split, <code>trySplit()</code> slices off an initial portion of the described elements into a new <code>Spliterator</code>, which is returned, and adjusts its state to describe the elements following the sliced-off portion. If the source can't be split, <code>trySplit()</code> returns <code>null</code>, indicating that the splitting isn't possible and that the caller should proceed sequentially. For sources whose <a href="#eo">encounter order</a> is significant (for example, arrays, <code>List</code>, or <code>SortedSet</code>), <code>trySplit()</code> must preserve this order; it must split off the initial portion of the remaining elements into the new <code>Spliterator</code>, and the current spliterator must describe the remaining elements in an order consistent with the original ordering.</p>
<p class="cye-lm-tag">The <code>Collection</code> implementations in the JDK have all been furnished with high-quality <code>Spliterator</code> implementations. Some sources admit better implementations than others: an <code>ArrayList</code> with more than one element can always be split cleanly and evenly; a <code>LinkedList</code> always splits poorly; and hash-based and tree-based sets can generally be split reasonably well.</p>
<h2 id="N1014E" class="ibm-h2">Building a stream pipeline</h2>
<p class="cye-lm-tag">A stream pipeline is built by constructing a linked-list representation of the stream source and its intermediate operations. In the internal representation, each stage of the pipeline is described by a bitmap of     <em>stream flags</em> that describe what's known about the elements at this stage of the stream pipeline. Streams uses these flags to optimize both the construction and execution of the stream. Table 1 shows the stream flags and their interpretations.</p>
<h5 id="table1" class="ibm-h5">Table 1. Stream flags</h5>
<table border="0" cellpadding="0" cellspacing="0" class="ibm-data-table"><thead xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><tr><th style="text-align:left; vertical-align:top"> Stream flag </th><th style="text-align:left; vertical-align:top"> Interpretation         </th></tr></thead><tbody xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><tr><td style="text-align:left; vertical-align:top"><code>SIZED</code></td><td style="text-align:left; vertical-align:top"> The size of the stream is known. </td></tr><tr><td style="text-align:left; vertical-align:top"><code>DISTINCT</code></td><td style="text-align:left; vertical-align:top"> The elements of the stream are distinct, according to <code>Object.equals()</code> for object streams, or according to <code>==</code> for primitive streams. </td></tr><tr><td style="text-align:left; vertical-align:top"><code>SORTED</code></td><td style="text-align:left; vertical-align:top"> The elements of the stream are sorted in the natural order. </td></tr><tr><td style="text-align:left; vertical-align:top"><code>ORDERED</code></td><td style="text-align:left; vertical-align:top"> The stream has a meaningful encounter order (see the "<a href="#eo">Encounter order</a>" section).</td></tr></tbody></table>
<p class="cye-lm-tag">The stream flags for the source stage are derived from the <code>characteristics</code> bitmap of the spliterator (spliterators support a larger set of flags than do streams). A high-quality spliterator implementation not only provides efficient element access and splitting but also describes the characteristics of the elements. (For example, the spliterator for a <code>HashSet</code> reports the <code>DISTINCT</code> characteristic, since the elements of a <code>Set</code> are known to be distinct.)</p>
<div class="ibm-pull-quote ibm-h3"><blockquote><p class="cye-lm-tag"><em class="dw-pullquote"><span class="dw-pullquote-open cye-lm-tag">“</span>In some cases, Streams can use knowledge of the source and     preceding operations to elide an operation entirely.<span class="dw-pullquote-close cye-lm-tag">”</span></em></p>
</blockquote></div><p class="cye-lm-tag">Each intermediate operation has a known effect on the stream flags; an operation can set, clear, or preserve the setting for each flag. For example, the <code>filter()</code> operation preserves the <code>SORTED</code> and <code>DISTINCT</code> flags but clears the <code>SIZED</code> flag; the <code>map()</code> operation clears the <code>SORTED</code> and <code>DISTINCT</code> flags but preserves the <code>SIZED</code> flag; and the <code>sorted()</code> operation preserves the <code>SIZED</code> and <code>DISTINCT</code> flags and injects the <code>SORTED</code> flag. As the linked-list representation of stages is constructed, the flags for the previous stage are combined with the behavior of the current stage to arrive at a new set of flags for the current stage.</p>
<p class="cye-lm-tag">In some cases, the flags make it possible to elide an operation entirely, as in the stream pipeline in Listing 1.</p>
<h5 id="listing" class="ibm-h5">Listing 1. Stream pipeline in which operations     can be automatically elided</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_410339" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">TreeSet&lt;</code><code class="htmlscript plain">String</code><code class="htmlscript plain">&gt; ts = ...</code></div><div class="line number2 index1 alt1"><code class="htmlscript plain">String[] sortedAWords = ts.stream()</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.filter(s -&gt; s.startsWith("a"))</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.sorted()</code></div><div class="line number5 index4 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.toArray();</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">The stream flags for the source stage include <code>SORTED</code>, because the source is a <code>TreeSet</code>. The <code>filter()</code> method preserves the <code>SORTED</code> flag, so the stream flags for the filtering stage also include the <code>SORTED</code> flag. Normally, the result of the <code>sorted()</code> method would be to construct a new pipeline stage, add it to the end of the pipeline, and return the new stage. However, because it's known that the elements are already sorted in natural order, the <code>sorted()</code> method is a no-op — it just returns the previous stage (the filtering stage), since sorting would be redundant. (Similarly, if the elements are known to be <code>DISTINCT</code>, the <code>distinct()</code> operation can be eliminated entirely.)</p>
<h2 id="N101F6" class="ibm-h2">Executing a stream pipeline</h2>
<p class="cye-lm-tag">When the terminal operation is initiated, the stream implementation picks an execution plan. Intermediate operations are divided into     <em>stateless</em> (<code>filter()</code>, <code>map()</code>, <code>flatMap()</code>) and <em>stateful</em> (<code>sorted()</code>, <code>limit()</code>, <code>distinct()</code>) operations. A stateless operation is one that can be performed on an element without knowledge of any of the other elements. For example, a filtering operation only needs to examine the current element to determine whether to include or eliminate it, but a sorting operation must see all the elements before it knows which element to emit first.</p>
<p class="cye-lm-tag">If the pipeline is executing sequentially, or is executing in parallel but consists of all stateless operations, it can be computed in a single pass. Otherwise, the pipeline is divided into sections (at stateful operation boundaries) and is computed in multiple passes.</p>
<p class="cye-lm-tag">Terminal operations are either <em>short-circuiting</em> (<code>allMatch()</code>, <code>findFirst()</code>) or     <em>non–short-circuiting</em> (<code>reduce()</code>, <code>collect()</code>, <code>forEach()</code>). If the terminal operation is non–short-circuiting, the data can be processed in bulk (using the <code>forEachRemaining()</code> method of the source spliterator, further reducing the overhead of accessing each element); if it's short-circuiting, it must be processed one element at a time (using <code>tryAdvance()</code>).</p>
<p class="cye-lm-tag">For sequential execution, Streams constructs a "machine" — a chain of <code>Consumer</code> objects whose structure matches that of the pipeline structure. Each of these <code>Consumer</code> objects knows about the next stage; when it receives an element (or is notified that there are no more elements), it sends zero or more elements to the next stage in the chain. For example, the <code>Consumer</code> associated with a <code>filter()</code> stage applies the filter predicate to the input element and either does or doesn't send it on to the next stage; the <code>Consumer</code> associated with a <code>map()</code> stage applies the mapping function to the input element and sends the result to the next stage. The <code>Consumer</code> associated with a stateful operation such as <code>sorted()</code> buffers elements until it sees the end of the input, and then it sends the sorted data to the next stage. The final stage in the machine implements the terminal operation. If this operation produces a result, such as <code>reduce()</code> or <code>toArray()</code>, this stage acts as accumulator for the result.</p>
<p class="cye-lm-tag">Figure 1 shows an animation (or, in certain browsers, a snapshot) of the "stream machine" for the following stream pipeline. (In Figure 1, yellow, green, and blue blocks enter the machine's first stage from the top, in sequence. In the first stage, each block is compressed into a smaller block and then falls into the second stage. There, a Pacman-like character swallows each yellow block, letting only the green and blue blocks fall into the third stage. Compressed blue and green blocks are alternately displayed on a computer screen.)</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_32232" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">blocks.stream()</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.map(block -&gt; block.squash())</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.filter(block -&gt; block.getColor() != YELLOW)</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">.forEach(block -&gt; block.display());</code></div></div></td></tr></tbody></table>
</div></div></div></span><h5 id="N1025E" class="ibm-h5">Figure 1. The stream machine (animations courtesy of     Tagir Valeev)</h5>
<img src="pics/fuse.svg" class="ibm-downsize" alt="Animated image of a stream machine." height="400px"> <div class="overlayrp"></div><p class="cye-lm-tag">Parallel execution does something similar, except that instead of creating a single machine, each worker thread gets its own copy of the machine and feeds its section of the data to it, and then the result of each per-thread machine is merged with the results of other machines to produce a final result.</p>
<p class="cye-lm-tag">Execution of stream pipelines can also be optimized through the use of stream flags. For example, the <code>SIZED</code> flag indicates that the size of the final result is known. The <code>toArray()</code> terminal operation can use this flag to preallocate the correct-size array; if the <code>SIZED</code> flag isn't present, it would have to guess at the array size and possibly copy the data if the guess is wrong.</p>
<div class="ibm-pull-quote ibm-h3"><blockquote><p class="cye-lm-tag"><em class="dw-pullquote"><span class="dw-pullquote-open cye-lm-tag">“</span>When performance is critical, it's valuable to understand     how the library works internally.<span class="dw-pullquote-close cye-lm-tag">”</span></em></p>
</blockquote></div><p class="cye-lm-tag">The presizing optimization is even more effective in parallel stream executions. In addition to the <code>SIZED</code> flag, another spliterator characteristic, <code>SUBSIZED</code>, means that not only is the size known, but that if the spliterator is split, the split sizes will be also known. (This is true for arrays and <code>ArrayList</code>, but not necessarily true for other splittable sources such as trees.) If the <code>SUBSIZED</code> characteristic is present, in a parallel execution the <code>toArray()</code> operation can allocate a single correct-sized array for the entire result, and individual threads (each working on a separate section of the input) can write their results directly into the correct section of the array — with no synchronization or copying needed. (In the absence of the <code>SUBSIZED</code> flag, each section is collected to an intermediate array and then copied to the final location.)</p>
<h2 id="eo" class="ibm-h2">Encounter order</h2>
<p class="cye-lm-tag">Another subtle consideration that influences the library's ability to optimize is <em>encounter order</em>. Encounter order refers to whether or not the order in which a source dispenses elements is significant to the computation. Some sources (such as hash-based sets and maps) have no meaningful encounter order. A stream flag, <code>ORDERED</code>, describes whether the stream has a meaningful encounter order or not. The spliterators for the JDK collections set this flag based on the specification of the collection; some intermediate operations might inject <code>ORDERED</code> (<code>sorted()</code>) or clear it (<code>unordered()</code>).</p>
<p class="cye-lm-tag">If the stream does have an encounter order, most stream operations must respect that order. For sequential executions, preserving encounter order is essentially free, because elements are naturally processed in the order in which they're encountered. Even in parallel, for many operations (stateless intermediate operations and certain terminal operations such as <code>reduce()</code>), respecting the encounter order doesn't impose any real costs. But for others (stateful intermediate operations, and terminal operations whose semantics are tied to encounter order, such as <code>findFirst()</code> or <code>forEachOrdered()</code>), the obligation to respect the encounter order in a parallel execution can be significant. If the stream has a defined encounter order, but that order isn't significant to the result, it might be possible to speed up parallel execution of pipelines containing order-sensitive operations by removing the <code>ORDERED</code> flag with the <code>unordered()</code> operation.</p>
<p class="cye-lm-tag">As an example of an operation that's sensitive to encounter order, consider <code>limit()</code>, which truncates a stream at a specified size. Implementing <code>limit()</code> in a sequential execution is trivial: Keep a counter of how many elements have been seen, and discard any elements after that. But in a parallel execution, implementing <code>limit()</code> is much more complicated; you have to keep the     <strong>first</strong>&nbsp;<code>N</code> elements. This requirement greatly constrains the ability to exploit parallelism; if the input is divided into sections, you don't know if the result of a section will be included in the final result until all the sections preceding that section have been completed. As a result, the implementation generally has the bad choice of not using all the cores that are available, or buffering the entire tentative result until you hit the target length.</p>
<p class="cye-lm-tag">If the stream has no encounter order, the <code>limit()</code> operation is free to choose <strong>any</strong>&nbsp;<code>N</code> elements, which admits a much more efficient execution. Elements can be sent downstream as soon as they're known, without any buffering, and the only coordination needed between threads is a semaphore to ensure that the target stream length isn't exceeded.</p>
<p class="cye-lm-tag">Another, more subtle example of the costs of encounter order is sorting. If encounter order is significant, the <code>sorted()</code> operation implements a <em>stable</em> sort (equal elements appear in the same order in the output as they do in the input), whereas for an unordered stream, stability — which has a cost — isn't required. A similar story exists for <code>distinct()</code>: If the stream has an encounter order, then for multiple equal input elements, <code>distinct()</code> must emit the <strong>first</strong> of them, whereas for an unordered stream, it can emit any of them — which again admits a much more efficient parallel implementation.</p>
<p class="cye-lm-tag">A similar situation arises when you aggregate with <code>collect()</code>. If you execute a <code>collect(groupingBy())</code> operation on an ordered stream, the elements corresponding to any key must be presented to the downstream collector in the order in which they appear in the input. Often, this order isn't significant to the application, and any order would do. In these cases, it might be preferable to select a     <em>concurrent</em> collector (such as <code>groupingByConcurrent())</code>, which is allowed to ignore encounter order and let all threads collect directly into a shared concurrent data structure (such as <code>ConcurrentHashMap</code>) rather than having each thread collecting into its own intermediate map, and then merging the intermediate maps (which can be expensive).</p>
<h2 id="N102F9" class="ibm-h2">Creating streams</h2>
<div class="ibm-pull-quote ibm-h3"><blockquote><p class="cye-lm-tag"><em class="dw-pullquote"><span class="dw-pullquote-open cye-lm-tag">“</span>It's easy to adapt existing data structures to dispense     streams.<span class="dw-pullquote-close cye-lm-tag">”</span></em></p>
</blockquote></div><p class="cye-lm-tag">While many of the classes in the JDK have been retrofitted to serve as stream sources, it's also easy to adapt existing data structures to dispense streams. To create a stream from an arbitrary data source, you need to create a <code>Spliterator</code> for the stream's elements and pass the spliterator to <code>StreamSupport.stream()</code>, along with a <code>boolean</code> flag indicating whether the resulting stream should be sequential or parallel.</p>
<p class="cye-lm-tag"><code>Spliterator</code> implementations can range considerably in quality, making trade-offs between the effort of implementation and the performance of stream pipelines that use spliterators as a source. The <code>Spliterator</code> interface has several methods that are essentially optional, such as <code>trySplit()</code>. If you don't want to implement splitting, you can always return <code>null</code> from <code>trySplit()</code>— but this means that streams using this <code>Spliterator</code> as a source will be unable to exploit parallelism to speed up the computation.</p>
<p class="cye-lm-tag">Considerations that affect the quality of a spliterator include:</p>
<ul class="ibm-bullet-list"><li>Does the spliterator report an accurate size?</li><li>Can the spliterator split the input at all?</li><li>Can it split the input into roughly equal sections?</li><li>Are the sizes of the splits predictable (reflected through the     <code>SUBSIZED</code> characteristics)?</li><li>Does the spliterator report all relevant characteristics?</li></ul><p class="cye-lm-tag">The easiest way to make a spliterator, but which results in the worst-quality result, is to pass an <code>Iterator</code> to <code>Spliterators.spliteratorUnknownSize()</code>. You can obtain a slightly better spliterator by passing an <code>Iterator</code> and a size to <code>Spliterators.spliterator</code>. But if stream performance is important — especially, parallel performance — implement the full <code>Spliterator</code> interface, including all applicable characteristics. The JDK sources for collection classes such as <code>ArrayList</code>, <code>TreeSet</code>, and <code>HashMap</code> provide examples of high-quality spliterators that you can emulate for your own data structures.</p>
<h2 id="N1034F" class="ibm-h2">Conclusion to Part 3</h2>
<p class="cye-lm-tag">While the performance of Streams out of the box is generally good (sometimes even better than the corresponding imperative code), having a firm grasp on how Streams works under the hood enables you to use the library with maximum efficiency, and to create custom adapters for deriving a stream from any data source. The next two <a href="http://www.ibm.com/developerworks/library/?search_by=Java+Streams,+Part"><em>Java Streams</em></a> series installments explore parallelism in depth.</p>
<!--CMA ID: 1030941--><!--Site ID: 1--><!--XSLT stylesheet used to transform this file: dw-document-html-8.0.xsl-->                   <!-- CENTER_6_4_CONTENT_COLUMN_END -->     </div> <br><hr>  <h2>Part 4 From concurrent to parallel</h2>
 <div id="ibm-content-main" class="dw-article cye-lm-tag">                 <!-- BEGIN_INTERIOR-COLUMNS --> <div class="ibm-columns dw-article-toc cye-lm-tag">     <!-- LEFT_6_2_CONTENT_COLUMN_BEGIN -->       <div id="dw-article-toc-container" class="ibm-col-6-2">         <div id="dw-article-toc-body" data-widget="scrollable" data-height="417" style="width: 380px; height: 417px;" class="nano has-scrollbar"><div class="nano-content" tabindex="-1" style="right: -17px;"> <h2>Contents</h2>
<div class="ibm-alternate-rule"><hr></div><ul role="directory" aria-label="Table of contents" class="ibm-plain-list"><li class="dw-highlight"><a onclick="tocLink('#ibm-pagetitle-h1')" role="link" tabindex="0">Introduction</a></li><li><a onclick="tocLink('#N10069')" role="link" tabindex="0">More cores, not faster cores</a></li><li><a onclick="tocLink('#N100B1')" role="link" tabindex="0">From concurrent to parallel</a></li><li><a onclick="tocLink('#N100FC')" role="link" tabindex="0">Parallelism</a></li><li><a onclick="tocLink('#exploiting_parallelism')" role="link" tabindex="0">Exploiting parallelism</a></li><li><a onclick="tocLink('#N1019E')" role="link" tabindex="0">Divide and conquer</a></li><li><a onclick="tocLink('#N101BF')" role="link" tabindex="0">Performance considerations</a></li><li><a onclick="tocLink('#N10208')" role="link" tabindex="0">Amdahl's law</a></li><li><a onclick="tocLink('#N10232')" role="link" tabindex="0">Conclusion to Part 4</a></li><li><a onclick="tocLink('#artdownload')" role="link" tabindex="0">Downloadable resources</a></li><li><a onclick="tocLink('#artrelatedtopics')" role="link" tabindex="0">Related topics</a></li><li><a onclick="tocLink('#icomments')" role="link" tabindex="0">Comments</a></li></ul>         </div><div class="nano-pane" style="opacity: 1; visibility: visible; display: none;"><div class="nano-slider" style="height: 20px; transform: translate(0px, 0px);"></div></div></div>     </div>     <!-- LEFT_6_2_CONTENT_COLUMN_END -->          <!-- CENTER_6_4_CONTENT_COLUMN_BEGIN -->     <div class="ibm-col-6-4 cye-lm-tag"> <p class="dw-article-series-head cye-lm-tag">Java Streams, Part 4</p>
         <h1 id="ibm-pagetitle-h1" class="ibm-h1">From concurrent to parallel</h1>
<p class="dw-article-subhead cye-lm-tag">Understanding the factors influencing parallel performance</p>
         <!-- Article Top Bar --> <div class="dw-article-authordate"><span class="dw-article-author cye-lm-tag"><a href="https://twitter.com/BrianGoetz">Brian Goetz</a></span><br><span class="dw-article-pubdate cye-lm-tag">Published on July 18,  2016</span></div>     </div>     <!-- Social -->     <div class="ibm-col-6-2 ibm-col-medium-6-4 ibm-col-small-6-2 dw-article-social">         <!-- Sharing links -->          </div>         </div>          <div id="dw-series-container" style="display: block;"><h3 class="ibm-h3" id="dw-series-heading">Content series:</h3>
<div data-widget="showhide" data-type="panel" class="ibm-show-hide ibm-widget-processed"><div class="ibm-container-body" id="dw-series-links" ><ul id="dw-series-list"><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-1-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 1: An introduction to the java.util.stream library</a></li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-2-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 2: Aggregating with Streams</a></li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-3-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 3: Streams under the hood</a></li><li class="dw-series-item">Part 4: From concurrent to parallel</li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-5-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 5: Parallel stream performance</a></li></ul></div></div></div>         <!-- Article Body -->                  <p class="cye-lm-tag">This fourth installment of the <a href="https://www.ibm.com/developerworks/views/global/libraryview.jsp?series_title_by=Java+Streams"><em>Java Streams</em></a> series explains factors that determine the effectiveness of parallel processing, putting them into historical and technical context. An understanding of these factors provides a foundation for making optimal use of the Streams library for parallel execution — and the <a href="https://www.ibm.com/developerworks/library/j-java-streams-5-brian-goetz/index.html">next installment</a> focuses on applying these principles directly to Streams.</p>
<h2 id="N10069" class="ibm-h2">More cores, not faster cores</h2>
<p class="cye-lm-tag">By around 2002, the techniques that chip designers had been using to deliver exponentially increasing performance had started to dry up. Increasing clock rates much further was impractical for various reasons, including power consumption and heat dissipation, and the techniques for doing more work per cycle (<em>instruction-level parallelism</em>) had also started to hit the point of diminishing returns.</p>
<p class="cye-lm-tag"><a href="https://en.wikipedia.org/wiki/Moore's_law">Moore's law</a> predicts that the number of transistors that can be packed onto a die doubles approximately every two years. When chip designers hit the     <em>frequency wall</em> in 2002, it wasn't because Moore's Law had run out of steam; we continued to see steady exponential growth in transistor counts. But while the ability to harness this ever-increasing transistor budget into <strong>faster cores</strong> had played out, chip designers could still use this increasing transistor budget to put <strong>more     cores</strong> on a single die. Figure 1 illustrates this trend with data from Intel processors, plotted on a log scale. The topmost (straight) line indicates exponential growth in transistor count, while the lines representing clock rate, power dissipation, and instruction-level parallelism all show a clear leveling off around 2002.</p>
<h5 id="N1008F" class="ibm-h5">Figure 1. Transistor counts and CPU performance for Intel CPUs     (image source: <a href="http://www.gotw.ca/publications/concurrency-ddj.htm">Herb         Sutter</a>)</h5>
<img src="pics/Par1Figure1.png" class="ibm-downsize" alt="Graph of transistor counts plotted against CPU performance for Intel CPUs"><div class="overlayrp"></div><p class="cye-lm-tag">Having more cores might enable greater power efficiency (cores not being actively used can be powered down independently), but it doesn't necessarily equate to better program performance — unless you can keep all the cores busy with useful work. Indeed, today's chips are not giving us as many cores as Moore's law would allow — largely because today's software cannot exploit them cost-effectively.</p>
<h2 id="N100B1" class="ibm-h2">From concurrent to parallel</h2>
<p class="cye-lm-tag">Throughout most of the the history of computing, the goal of concurrency has largely stayed the same — improve performance by increasing CPU utilization — but the techniques (and measure of performance) have changed. In the days of single-core systems, concurrency was mostly about     <em>asynchrony</em>— allowing an activity to relinquish the CPU while waiting for an I/O to complete. Asynchrony could improve both <em>responsiveness</em> (not freezing the UI while a background activity is in progress) and     <em>throughput</em> (allowing another activity to use the CPU while waiting for the I/O to complete). In some concurrency models (Actors and Communicating Sequential Processes [CSP], for example) the concurrency model contributed to the structure of the program, but for the most part (for better or worse) we just used concurrency as needed for performance.</p>
<div class="ibm-pull-quote ibm-h3"><blockquote><p class="cye-lm-tag"><em class="dw-pullquote"><span class="dw-pullquote-open cye-lm-tag">“</span>Factors that influence the effectiveness of parallelism     include the problem itself, the algorithm used to solve the problem,     the runtime support for task decomposition and scheduling, and the     size and memory locality of the data set.<span class="dw-pullquote-close cye-lm-tag">”</span></em></p>
</blockquote></div><p class="cye-lm-tag">As we moved into the multicore era, the primary application of concurrency was to factor the workload into independent, coarse-grained tasks — such as user requests — with the aim of increasing throughput by processing multiple requests simultaneously. Around this time, the Java libraries acquired tools such as thread pools, semaphores, and futures, which are well suited to task-based concurrency.</p>
<p class="cye-lm-tag">As core counts continue to increase, however, enough "naturally occurring" tasks might not be available to keep all the cores busy. With more cores available than tasks, another performance goal becomes attractive: reducing <em>latency</em> by using multiple cores to complete a single task more quickly. Not all tasks are easily amenable to this sort of decomposition; the ones that work best are data-intensive queries wherein the same operations are done over a large data set.</p>
<p class="cye-lm-tag">Sadly, the terms <em>concurrency</em> and <em>parallelism</em> don't have standard definitions, and they are often (erroneously) used interchangeably. Historically, <em>concurrency</em> described a property of a <strong>program</strong>— the degree to which a program is structured as the interaction of cooperating computational activities — whereas <em>parallelism</em> was a property of a program's <strong>execution</strong>, describing the degree to which things actually happen simultaneously. (Under this definition, concurrency is the <strong>potential</strong> for parallelism.) This distinction was useful when true concurrent execution was mostly a theoretical concern, but it has become less useful over time.</p>
<p class="cye-lm-tag">More modern curricula describe <em>concurrency</em> as being about correctly and efficiently controlling access to shared resources, whereas     <em>parallelism</em> is about using more resources to solve a problem faster. Constructing thread-safe data structures is the domain of concurrency, as enabled by primitives such as locks, events, semaphores, coroutines, or software transactional memory (STM). On the other hand, parallelism uses techniques like partitioning or sharding to enable multiple activities to make progress on the task <strong>without</strong> coordination.</p>
<p class="cye-lm-tag">Why is this distinction important? After all, concurrency and parallelism have the common goal of getting multiple things done simultaneously. But there's a big difference in how easy the two are to get right. Making concurrent code correct with coordination primitives such as locks is difficult, error prone, and unnatural. Making parallel code correct by arranging that each worker has its own portion of the problem to work on is comparatively simpler, safer, and more natural.</p>
<h2 id="N100FC" class="ibm-h2">Parallelism</h2>
<p class="cye-lm-tag">While the mechanics of parallelism are often straightforward, the hard part is knowing <strong>when</strong> to use it. Parallelism is strictly an optimization; it is a choice to use more resources for a particular computation, in the hope of getting to the answer faster — but you always have the option of performing the computation sequentially. Unfortunately, using more resources is no guarantee of getting to the answer faster — or even as fast. And, if parallelism offers us no return (or negative return) on additional resource consumption, we shouldn't use it. Of course, the return is highly situational, so there's no universal answer. But we have tools to help us evaluate if parallelism will be effective in a given situation: analysis, measurement, and performance requirements.</p>
<p class="cye-lm-tag">This article focuses mostly on analysis — exploring which kinds of computations tend to parallelize well and which don't. As a rule of thumb, though, prefer using a sequential execution unless you have reason to believe that you will get a speedup from parallelism, <strong>and</strong> the speedup actually matters according to your performance requirements. (Many programs are already fast enough, so effort spent optimizing them could be better spent on more value-creating activities, such as improving usability or reliability.)</p>
<p class="cye-lm-tag">The measure of parallel effectiveness, called <em>speedup</em>, is simply the ratio of parallel runtime to sequential runtime. Choosing parallelism (assuming it delivers a speedup) is a deliberate choice to value time over CPU and power utilization. A parallel execution always does more work than a sequential one, since — in addition to solving the problem — it also must decompose the problem, create and manage tasks to describe the subproblems, dispatch and wait for those tasks, and merge their results. So the parallel execution always starts out "behind" the sequential one and hopes to make up for the initial deficit through economy of scale.</p>
<p class="cye-lm-tag">For parallelism to be the better choice, several things must come together. We need a problem that admits a parallel solution in the first place — which not all problems do. Then, we need an implementation of the solution that exploits the inherent parallelism. We need to ensure that the techniques used to implement parallelism don't come with so much overhead that we squander the cycles we throw at the problem. And we need     <strong>enough data</strong> so that we can achieve the economy of scale needed to get a speedup.</p>
<h2 id="exploiting_parallelism" class="ibm-h2">Exploiting parallelism</h2>
<p class="cye-lm-tag">Not all problems are equally amenable to parallelization. Consider the following problem: Given a function <code>f</code>, which we'll assume is expensive to compute, define <code>g</code> as follows:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_107506" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">g(0) = f(0) </code></div><div class="line number2 index1 alt1"><code class="htmlscript plain">g(n) = f( g(n-1) ), for n &gt; 0</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">We could implement a parallel algorithm for <code>g</code> and measure its speedup, but we don't need to; we can look at the problem and immediately see that it is fundamentally sequential. To see this, we can rewrite <code>g(n)</code> slightly differently:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_7272" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">g(n) = f( f( ... n times ... f(0) ... )</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">With this rewrite, we see that we can't even start computing <code>g(n)</code> until we finish computing <code>g(n-1)</code>. In the dataflow dependency diagram for computing <code>g(4)</code>, shown in Figure 2, each value of <code>g(n)</code> depends on the previous value <code>g(n-1)</code>.</p>
<h5 id="N10152" class="ibm-h5">Figure 2. Dataflow dependency graph for function     <code>g</code></h5>
<img src="pics/par1Figure2.png" class="ibm-downsize" alt="Graph of dataflow dependency for function g; each value of g(n) depends on the previous value g(n-1)." height="400px"><p class="cye-lm-tag">You might be tempted to conclude that the problem stems from the fact that <code>g(n)</code> is defined recursively, but that's not the case. Consider the slightly different problem of computing the function <code>h(n)</code>:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_502783" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">h(0) = f(0)</code></div><div class="line number2 index1 alt1"><code class="htmlscript plain">h(n) = f(n) + h(n-1)</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">If we write the obvious implementation for computing <code>h(n)</code>, we end up with a dataflow dependency graph like the one shown in Figure 3, in which each <code>h(n)</code> depends on <code>h(n-1)</code>.</p>
<h5 id="N10175" class="ibm-h5">Figure 3. Dataflow dependency graph for a naive implementation     of function <code>h</code></h5>
<img src="pics/par1Figure3.png" class="ibm-downsize" alt="Dependency graph of dataflow dependency for naive implementation of function h; each h(n) depends on h(n-1)."  height="400px"><div class="overlayrp"></div><p class="cye-lm-tag">However, if we rewrite <code>h(n)</code> in a different way, we can immediately see how this problem has exploitable parallelism. We can compute each of the terms independently and then add them up (which also admits parallelism):</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_976108" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">h(n) = f(0) + f(1) + .. + f(n)</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">The result is a dataflow dependency graph like the one shown in Figure 4, in which each <code>h(n)</code> can be computed independently.</p>
<h5 id="N1018F" class="ibm-h5">Figure 4. Dataflow dependency graph for function     <code>h</code></h5>
<img src="pics/par1Figure4.png" class="ibm-downsize" alt="Dependency graph of dataflow dependency for better algorithm for computing function h; each h(n) can be computed independently."  width="400px"><div class="overlayrp"></div><p class="cye-lm-tag">These examples show us two things: first, that similar-looking problems can have vastly different degrees of exploitable parallelism; and second, that the "obvious" implementation of a solution to a problem with exploitable parallelism might not necessarily <strong>exploit</strong> that parallelism. To have any chance of getting a speedup, we need both.</p>
<h2 id="N1019E" class="ibm-h2">Divide and conquer</h2>
<p class="cye-lm-tag">The standard technique for attacking exploitable parallelism is called     <em>recursive decomposition</em>, or <em>divide and conquer</em>. In this approach, we repeatedly divide the problem into subproblems until the subproblems are small enough that it makes more sense to solve them sequentially; we then solve the subproblems in parallel, and combine the partial results of the subproblems to derive a total result.</p>
<p class="cye-lm-tag"> Listing 1 illustrates a typical divide-and-conquer solution in pseudocode, using a hypothetical <code>CONCURRENT</code> primitive for concurrent execution.</p>
<h5 id="listing1" class="ibm-h5">Listing 1. Recursive decomposition</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_834754" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">R solve(Problem&lt;</code><code class="htmlscript plain">R</code><code class="htmlscript plain">&gt; problem) {</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">if (problem.isSmall())</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">return problem.solveSequentially();</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">R leftResult, rightResult;</code></div><div class="line number5 index4 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">CONCURRENT {</code></div><div class="line number6 index5 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">leftResult = solve(problem.leftHalf());</code></div><div class="line number7 index6 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">rightResult = solve(problem.rightHalf());</code></div><div class="line number8 index7 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">}</code></div><div class="line number9 index8 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">return problem.combine(leftResult, rightResult);</code></div><div class="line number10 index9 alt1"><code class="htmlscript plain">}</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">Recursive decomposition is appealing because it is <strong>simple</strong> (especially so when dealing with data structures that are already defined recursively, such as trees). Parallel code like that in Listing 1 is portable across a range of computing environments; it works efficiently with one core or with many, and it need not concern itself with the complexities of coordinating access to shared mutable state — because there is no shared mutable state. Partitioning the problem into subproblems, and arranging for each task to only access the data from a particular subproblem, generally requires no coordination between threads.</p>
<h2 id="N101BF" class="ibm-h2">Performance considerations</h2>
<p class="cye-lm-tag">With <a href="#listing1">Listing 1</a> as our model, we can now proceed to analyze the conditions under which parallelism could offer an advantage. Two additional algorithmic steps are introduced by divide-and-conquer — dividing the problem, and combining the partial results — and each of these can be more or less friendly to parallelism. Another factor that can affect parallel performance is the efficiency of the parallelism primitives themselves — illustrated by the hypothetical <code>CONCURRENT</code> mechanism in <a href="#listing1">Listing 1</a>'s pseudocode. An additional two factors are properties of the data set: its size and its memory locality. We consider each of these conditions in turn.</p>
<p class="cye-lm-tag">Some problems, such as the <code>g(n)</code> function in the "<a href="#exploiting_parallelism">Exploiting parallelism</a>" section, do not admit decomposition at all. But even when a problem admits decomposition, decomposing it can have a cost. (At the very least, decomposing a problem involves creating a description of the subproblem.) For example, the decomposition step of the <a href="https://en.wikipedia.org/wiki/Quicksort">Quicksort</a> algorithm requires finding a pivot point, which is <em>O(n)</em> in the size of the problem, because it involves examining and possibly updating all the data. This requirement is much more expensive than the partitioning step of a problem like "find the sum of an array of elements," whose partitioning step is <em>O(1)</em>— "find the average of the top and bottom indices." And, even if the problem can be efficiently decomposed, if the two subproblems are of vastly unequal size, we might not have exposed much exploitable parallelism.</p>
<p class="cye-lm-tag">Similarly, when we solve two subproblems, we must combine the results. If our problem is "remove duplicate elements," the combination step requires the merging of two sets; if we want a flat representation of the result, this step is also <em>O(n)</em>. On the other hand, if our problem is "find the sum of an array," our combination step is again <em>O(1)</em>— "add two numbers."</p>
<p class="cye-lm-tag">Managing tasks to be executed concurrently can involve several possible sources of efficiency loss, such as the inherent latency of handing off data from one thread to another or the risk of contention for shared data structures. The <em>fork-join</em> framework — added in Java SE 7 for managing fine-grained, computation-intensive tasks — is designed to minimize many common sources of inefficiency in parallel dispatch. The <code>java.util.stream</code> library uses the fork-join framework for implementing parallel execution.</p>
<p class="cye-lm-tag">Finally, we must consider the data. If the data set is small, it will be hard to extract any sort of speedup, because of the startup costs imposed by parallel execution. Similarly, if the data set exhibits poor memory locality (pointer-rich data structures such as graphs, as opposed to arrays), it is likely that — with today's typically memory-bound systems — executing in parallel will simply result in many threads waiting for data from the cache, rather than effectively using the cores to compute the answer faster.</p>
<p class="cye-lm-tag">Each of these factors can steal from our speedup; in some situations, they can not only erase the speedup but even cause a slowdown.</p>
<h2 id="N10208" class="ibm-h2">Amdahl's law</h2>
<p class="cye-lm-tag"><a href="https://en.wikipedia.org/wiki/Amdahl's_law">Amdahl's law</a> describes how the sequential portion of a computation limits the possible parallel speedup. Most problems have some amount of work that cannot be parallelized; this is called the <em>serial fraction</em>. For example, if you are going to copy the data from one array to another, the copying might be parallelizable, but the allocation of the target array — which is inherently sequential — must happen before any copying can happen.</p>
<p class="cye-lm-tag">Figure 5 shows the effects of Amdahl's law. The various curves illustrate the best possible speedup allowed by Amdahl's Law as a function of the number of processors available, for varying parallel fractions (the complement of the serial fraction.) If, for example, the parallel fraction is .5 (half the problem must be executed sequentially) and an infinite number of processors are available, Amdahl's law tells us that the best speedup we can hope for is 2x. This is intuitively sensible; even if we could reduce the cost of the parallelizable part to zero through parallelization, we still have half the problem to solve sequentially.</p>
<h5 id="N1021C" class="ibm-h5">Figure 5. Amdahl's law (image source: <a href="https://commons.wikimedia.org/w/index.php?curid=6678551">Wikimedia Commons</a>)</h5>
<img src="pics/Par1Figure5.png" class="ibm-downsize" alt="Graph of Amdahl's law"><div class="overlayrp"></div><p class="cye-lm-tag">The model implied by Amdahl's Law — that some fraction of the work must be completely sequential and the rest is perfectly parallelizable — is overly simplistic. Nonetheless, it is still useful for understanding the factors that inhibit parallelism. The ability to spot, and reduce, the serial fraction is a key factor in being able to craft more efficient parallel algorithms.</p>
<p class="cye-lm-tag">Another way to interpret Amdahl's law is: If you have a 32-core machine, for every cycle you spend setting up a parallel computation, that's 31 cycles that can't be applied to solving the problem. And if you've split the problem in two, that's still 30 cycles going to waste on every clock tick. Only when you can split off enough work to keep all the processors busy are you fully up and running — and if you don't get there quickly enough (or stay there long enough), it's going to be hard to get a good speedup.</p>
<h2 id="N10232" class="ibm-h2">Conclusion to Part 4</h2>
<p class="cye-lm-tag">Parallelism is a trade-off of using more compute resources in the hope of getting a speedup. While in theory we can speed up a problem by a factor of <em>N</em> by using <em>N</em> cores, reality usually falls far short of this goal. Factors that influence the effectiveness of parallelism include the problem itself, the algorithm used to solve the problem, the runtime support for task decomposition and scheduling, and the size and memory locality of the data set. <a href="https://www.ibm.com/developerworks/library/j-java-streams-5-brian-goetz/index.html">Part 5</a> of  <a href="http://www.ibm.com/developerworks/library/?search_by=Java+Streams,+Part"><em>Java Streams</em></a> applies these considerations to the Streams library and shows how (and why) some stream pipelines parallelize better than others.</p>
<!--CMA ID: 1034699--><!--Site ID: 1--><!--XSLT stylesheet used to transform this file: dw-document-html-8.0.xsl-->                   <!-- CENTER_6_4_CONTENT_COLUMN_END -->     </div>    </div>         <!--Rating_Meta_BEGIN--><div class="metavalue">static.content.url=http://www.ibm.com/developerworks/js/artrating/</div><div class="metavalue">SITE_ID=1</div><div class="metavalue">Zone=Java development, Big data and analytics</div><div class="metavalue">ArticleID=1034699</div><div class="metavalue">ArticleTitle=Java Streams, Part 4: From concurrent to parallel</div><div class="metavalue">publish-date=07182016</div><script language="javascript" type="text/javascript">document.write('<div class="metavalue">url='+location.href.replace(/</g,  '%3C')+'</div>');</script><div class="metavalue">url=https://www.ibm.com/developerworks/java/library/j-java-streams-4-brian-goetz/index.html</div><!--Rating_Meta_END-->     </div> <br><hr> <h2>Part 5 Parallel stream performance</h2>
 <div class="ibm-col-6-4 cye-lm-tag"> <p class="dw-article-series-head cye-lm-tag">Java Streams, Part 5</p>
         <h1 id="ibm-pagetitle-h1" class="ibm-h1 cye-lm-tag">Parallel stream performance</h1>
<p class="dw-article-subhead cye-lm-tag">Optimizing stream pipelines for parallel processing</p>
         <!-- Article Top Bar --> <div class="dw-article-authordate"><span class="dw-article-author cye-lm-tag"><a href="https://twitter.com/BrianGoetz">Brian Goetz</a></span><br><span class="dw-article-pubdate cye-lm-tag">Published on July 18,  2016</span></div>     </div>     <!-- Social -->     <div class="ibm-col-6-2 ibm-col-medium-6-4 ibm-col-small-6-2 dw-article-social">         <!-- Sharing links -->          </div>         </div>          <div id="dw-series-container" style="display: block;"><h3 class="ibm-h3" id="dw-series-heading">Content series:</h3>
<div data-widget="showhide" data-type="panel" class="ibm-show-hide ibm-widget-processed"><div class="ibm-container-body" id="dw-series-links" ><ul id="dw-series-list"><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-1-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 1: An introduction to the java.util.stream library</a></li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-2-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 2: Aggregating with Streams</a></li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-3-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 3: Streams under the hood</a></li><li class="dw-series-item"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-4-brian-goetz/index.html?ca=drs-" class="dw-series-article-link">Part 4: From concurrent to parallel</a></li><li class="dw-series-item">Part 5: Parallel stream performance</li></ul></div></div></div>         <!-- Article Body -->                  <p class="cye-lm-tag"><a href="http://www.ibm.com/developerworks/java/library/j-java-streams-4-brian-goetz/index.html">Part 4</a> of <a href="https://www.ibm.com/developerworks/views/global/libraryview.jsp?series_title_by=Java+Streams"><em>Java     Streams</em></a>  discussed factors that can influence the effectiveness of parallelization. These factors include characteristics of the problem, the algorithm used to implement the solution, the runtime framework used to schedule tasks for parallel execution, and the size and memory layout of the data set. This installment applies these concepts to the Streams library and examines why some stream pipelines parallelize better than others.</p>
<h2 id="N10066" class="ibm-h2">Parallel streams</h2>
<p class="cye-lm-tag">As you saw in <a href="http://www.ibm.com/developerworks/java/library/j-java-streams-3-brian-goetz/index.html">Part 3</a>, a stream pipeline consists of a stream source, zero or more intermediate operations, and a terminal operation. To execute a stream pipeline, we construct a "machine" that implements the intermediate and terminal operations, into which we feed the elements from the source. To execute a stream pipeline in parallel, we partition the source data into segments via recursive decomposition, using the <code>Spliterator</code> method <code>trySplit()</code>. The effect is to create a binary computation tree whose leaf nodes each correspond to a segment of the source data, and whose internal nodes each correspond to a point where the problem has been split into subtasks, and the results of two subtasks need to be combined. A sequential execution constructs one machine for the entire data set; a parallel execution constructs one machine for each segment of the source data, producing a partial result for each leaf. We then proceed up the tree, merging the partial results into bigger results, according to a merge function that is specific to the terminal operation. For example, for terminal operation <code>reduce()</code>, the binary operator used for reduction is also the merge function; for <code>collect()</code>, the <code>Collector</code> has a merge function used to merge one result container into another.</p>
<p class="cye-lm-tag">The previous installment identified several factors that might cause a parallel execution to lose efficiency:</p>
<ul class="ibm-bullet-list"><li>The source is expensive to split, or splits unevenly.</li><li>Merging partial results is expensive.</li><li>The problem doesn't admit sufficient exploitable parallelism.</li><li>The layout of the data results in poor access locality.</li><li>There's not enough data to overcome the startup costs of     parallelism.</li></ul><p class="cye-lm-tag">We now examine each of these considerations, with an eye toward how they manifest in parallel stream pipelines.</p>
<h2 id="N100AC" class="ibm-h2">Source splitting</h2>
<p class="cye-lm-tag">With parallel streams, we use the <code>Spliterator</code> method <code>trySplit()</code> to split a segment of the source data in two. Each node in the computation tree corresponds to a binary split, forming a binary tree. Ideally, this tree would be balanced — with each leaf node representing exactly the same amount of work — and the cost of splitting would be zero.</p>
<p class="cye-lm-tag">This ideal is not achievable in practice, but some sources come much closer than others. Arrays are the best case. We can describe a segment of an array by using a reference to the array base and integral offsets of the start and end of the segment. The cost of splitting this segment into two equal segments is cheap: We compute the midpoint of the segment, create a new descriptor for the first half, and move the starting index for the current segment to the first element in the in the second half.</p>
<p class="cye-lm-tag">Listing 1 shows the code for <code>trySplit()</code> in <code>ArraySpliterator</code>. Arrays have low split costs — a few arithmetic operations and an object creation; they also split evenly (leading to balanced computation trees). The <code>Spliterator</code> for <code>ArrayList</code> has the same desirable characteristics. (As a bonus, when splitting arrays we also know the exact size of all splits, which allows us to optimize away copies in some stream pipelines.) </p>
<h5 id="N100D2" class="ibm-h5">Listing 1.     Implementation of ArraySpliterator.trySplit().</h5>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_912560" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">public Spliterator&lt;</code><code class="htmlscript plain">T</code><code class="htmlscript plain">&gt; trySplit() {</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">int lo = index, mid = (lo + fence) &gt;&gt;&gt; 1;</code></div><div class="line number3 index2 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">return (lo &gt;= mid)</code></div><div class="line number4 index3 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">? null</code></div><div class="line number5 index4 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">: new ArraySpliterator&lt;&gt;(array,</code></div><div class="line number6 index5 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">lo, index = mid,</code></div><div class="line number7 index6 alt2"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">characteristics);</code></div><div class="line number8 index7 alt1"><code class="htmlscript plain">}</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">On the other hand, a linked list splits terribly. The cost of splitting is poor — to find the midpoint, we must traverse half the list, one node at a time. To lower splitting costs, we might accept more unbalanced splits — but this still doesn't help much. In the extreme case, we end up with a pathologically unbalanced (right-heavy) tree, where each split consists only of <code>(<em>first element</em>, <em>rest of list</em>)</code>. So, instead of <em>O(lg n)</em> splits, we have <em>O(n)</em> splits, which requires     <em>O(n)</em> combining steps. We're left with the bad choice between a computation tree that's very expensive to create (limiting parallelism by contributing to the serial fraction of <a href="https://en.wikipedia.org/wiki/Amdahl's_law">Amdahl's law</a>), and a computation tree that admits relatively little parallelism and has high combination costs (because it's so unbalanced.) That said, it's not     <strong>impossible</strong> to get parallelism out of a linked list — if the operations being performed for each node are sufficiently expensive. (See <a href="#thenqmodel">"The <em>NQ</em>     model."</a>)</p>
<p class="cye-lm-tag">Binary trees (such as <code>TreeMap</code>) and hash-based collections (such as <code>HashSet</code>) split better than linked lists, but not as well as arrays. Binary trees are fairly cheap to split in two, and if the tree is relatively balanced, the resulting computation tree will be as well. We implement <code>HashMap</code> as an array of buckets, where each bucket is a linked list. If the hash function spreads the elements well over the buckets, the collection should split relatively well (until you get down to a single bucket, and then you're back to a linked list, which ideally is small). However, both tree-based and hash-based collections generally don't split as predictably as arrays — we can't predict the size of the resulting splits, so we lose out on the ability to optimize away copies in some cases.</p>
<h2 id="N1010D" class="ibm-h2">Generators as sources</h2>
<p class="cye-lm-tag">Not all streams use a collection as their source; some use a generator function, such as <code>IntStream.range()</code>. The considerations that apply to collection sources can be applied directly to generators as well.</p>
<p class="cye-lm-tag">The next two examples show two ways to generate a stream consisting of integers 0 to 99. This code uses <code>Stream.iterate()</code> (the three-argument version of <code>iterate()</code> was added in Java 9):</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_772396" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">IntStream stream1 = IntStream.iterate(0, n -&gt; n &lt; </code><code class="htmlscript plain">100</code><code class="htmlscript plain">,</code></div><div class="line number2 index1 alt1"><code class="htmlscript spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="htmlscript plain">n -&gt; n + 1);</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">And this code uses <code>IntStream.range()</code>:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_261004" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">IntStream stream2 = IntStream.range(0, 100);</code></div></div></td></tr></tbody></table>
</div></div></div></span><p class="cye-lm-tag">The two examples produce the same results, but have dramatically different splitting characteristics — and therefore will have dramatically different parallel performance.</p>
<p class="cye-lm-tag"><code>Stream.iterate()</code> takes an initial value and two functions — one to produce the next value, and one to determine whether to stop producing elements — just like a <code>for</code>-loop. It's intuitively clear that this generator is fundamentally sequential: It cannot produce element <em>n</em> until it has produced element     <em>n-1</em>. As a result, splitting a sequential generator function has the same characteristics as splitting a linked list (the bad choice between high split costs and highly uneven splitting) and results in similarly poor parallelism.</p>
<p class="cye-lm-tag">On the other hand, the <code>range()</code> generator splits more like an array — it's easy and cheap to compute the midpoint of the range, without having computed the intervening elements.</p>
<p class="cye-lm-tag">Although the design of the Streams library was heavily influenced by the principles of functional programming, the difference in parallel performance characteristics between the two generator functions in the preceding examples illustrates a potential trap for those with a functional programming background. In functional programming, it's common and natural to generate a range by lazily consuming from an infinite stream constructed by iterative function application — but this idiom arose in a time when data-parallelism was an entirely theoretical concept. Functional programmers might easily reach for the familiar <code>iterate</code> idiom without immediately realizing the inherent sequentiality of this approach.</p>
<h2 id="N10151" class="ibm-h2">Result combination</h2>
<p class="cye-lm-tag">Splitting the source — efficiently and evenly, or not — is a necessary cost to enable parallel computation. If we're lucky, the cost of splitting is modest enough that we can start forking off work early, avoiding running afoul of Amdahl's law.</p>
<p class="cye-lm-tag">Every time we split the source, we accrue an obligation to combine the intermediate results of that split. After the leaf nodes have completed the work on their segment of the input, we proceed back up the tree, combining results as we go.</p>
<p class="cye-lm-tag">Some combining operations — such as reduction with addition — are cheap. But others — such as merging two sets — are much more expensive. The amount of time spent in the combination step is proportional to the depth of the computation tree; a balanced tree will have depth of <em>O(lg n)</em>, whereas a pathologically unbalanced tree (such as that we get from splitting a linked list or an iterative generating function) will have depth of <em>O(n)</em>.</p>
<p class="cye-lm-tag">Another problem with expensive merges is that the last merge — in which two half-results are being merged — will be performed sequentially (because there is no other work left to do). Stream pipelines whose merge steps are <em>O(n)</em>— such as those using the <code>sorted()</code> or <code>collect(Collectors.joining())</code> terminal operations — might see their parallelism limited by this effect.</p>
<div class="ibm-pull-quote ibm-h3"><blockquote><p class="cye-lm-tag"><em class="dw-pullquote"><span class="dw-pullquote-open cye-lm-tag">“</span>You might be surprised by the time and space costs of     parallel execution where operations are tied to encounter order. With     sequential execution, the obvious implementation is usually one in     which we traverse the input in encounter order, so a dependence on     encounter order is rarely either visible or costly. In parallel, such     dependencies can be very costly<span class="dw-pullquote-close cye-lm-tag">”</span></em></p>
</blockquote></div><h2 id="N10183" class="ibm-h2">Operation semantics</h2>
<p class="cye-lm-tag">Just as some sources — such as linked list or iterative generator functions — are inherently sequential, some stream operations also have an inherently sequential aspect, which can serve as an impediment to parallelism. These usually are operations whose semantics are defined in terms of <em>encounter order</em>.</p>
<p class="cye-lm-tag">For example, the <code>findFirst()</code> terminal operation yields the first element in the stream. (This operation is typically combined with filtering, so it usually ends up meaning "find the first element that satisfies some condition.") Implementing <code>findFirst()</code> sequentially is extremely cheap: Push data through the pipeline until some result is produced, and then stop. In parallel, we can easily parallelize the upstream operations, but when a result is produced by some subtask, we're not done. We still have to wait for all the subtasks that come earlier in the encounter order to finish. (At least we can cancel any subtasks that appear later in the encounter order.) A parallel execution pays all the costs of decomposition and task management, but is less likely to reap the benefits. On the other hand, the terminal operation <code>findAny()</code> is much more likely to reap a parallel speedup, because it keeps all the cores busy searching for a match, and can terminate immediately when it finds one.</p>
<p class="cye-lm-tag">Another terminal operation whose semantics are tied to encounter order is <code>forEachOrdered()</code>. Again, while it's often possible to fully parallelize the execution of the intermediate operations, the final applicative step is sequentialized. On the other hand, the <code>forEach()</code> terminal operation is unconstrained by encounter order. The applicative step can be executed for each element at whatever time and in whatever thread the element is made available.</p>
<p class="cye-lm-tag">Intermediate operations, such as <code>limit()</code> and <code>skip()</code>, can be constrained by encounter order as well. The <code>limit(n)</code> operation truncates the input stream after the     <em>first n</em> elements. Like <code>findFirst()</code>, when elements are produced by some task, <code>limit(n)</code> must wait for all the tasks that precede it in the encounter order to finish before it knows whether to push those elements to the remainder of the pipeline — and it must buffer the produced elements until it knows whether or not they are needed. (For an <em>unordered</em> stream, <code>limit(n)</code> is allowed to select <em>any n</em> elements — and like <code>findAny()</code>, is much more parallel-friendly.)</p>
<p class="cye-lm-tag">You might be surprised by the time and space costs of parallel execution where operations are tied to encounter order. The obvious sequential implementations of <code>findFirst()</code> and <code>limit()</code> are simple, efficient, and require almost no space overhead, but the parallel implementations are complex and often involve considerable waiting and buffering. With sequential execution, the obvious implementation is usually one in which we traverse the input in encounter order, so a dependence on encounter order is rarely either visible or costly. In parallel, such dependencies can be very costly.</p>
<p class="cye-lm-tag">Fortunately, these dependencies on encounter order often can be eliminated through small changes to the pipeline. Frequently, we can replace <code>findFirst()</code> with <code>findAny()</code> without any loss of correctness. Similarly, as we saw in Part 3, by making the stream unordered via the <code>unordered()</code> operation, we can often remove the encounter-order dependence inherent in <code>limit()</code>, <code>distinct()</code>, <code>sorted()</code>, and <code>collect()</code> with no loss of correctness.</p>
<p class="cye-lm-tag">The various hazards to parallel speedup that we've looked at so far can be cumulative. Just as the three-argument <code>iterate()</code> source was far worse than the range constructor, combining the two-argument <code>iterate()</code> source with <code>limit()</code> is even worse, as it combines a sequential generation step with an encounter-order-sensitive operation. For example, here's the least parallel-friendly way to generate a range of integers:</p>
<span class="dw-code-nohighlight cye-lm-tag"><div class="ibm-syntax-container"><div><div id="highlighter_561202" class="syntaxhighlighter nogutter  htmlscript"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="htmlscript plain">IntStream stream3 = IntStream.iterate(0, n -&gt; n+1).limit(100);</code></div></div></td></tr></tbody></table>
</div></div></div></span><h2 id="N101F7" class="ibm-h2">Memory locality</h2>
<p class="cye-lm-tag">Modern computer systems employ sophisticated multilevel caches to keep frequently used data as close (literally — speed of light is a limiting factor!) to the CPU as possible. Fetching data from L1 cache can easily be 100 times faster than fetching data from main memory. The more efficiently the CPU can predict which data will be needed next, the more cycles the CPU spends doing computation, and the fewer it spends waiting for data.</p>
<p class="cye-lm-tag">Data is paged into cache at the granularity of <em>cache lines</em>; today's x86 chips use a cache line size of 64 bytes. This rewards programs that have good <em>memory locality</em>— the propensity to access memory locations that are close to locations that have been recently accessed. Proceeding linearly through an array not only has excellent locality, but is also further rewarded by     <em>prefetch</em>— when a linear pattern of memory access is detected, the hardware begins prefetching the next cache-line's worth of memory on the assumption that it will probably be needed soon.</p>
<p class="cye-lm-tag">Mainstream Java implementations lay out the fields of an object, and the elements of an array, contiguously in memory (though fields are not necessarily laid out in the order declared in the source file). Accesses of fields or array elements that are "near" the most recently accessed field or element have a good chance of hitting data that is already in cache. On the other hand, references to other objects are represented as pointers, so dereferencing an object reference is more likely to hit data that is not already in cache, causing a delay.</p>
<p class="cye-lm-tag">An array of primitives offers the best locality possible. After the initial dereference of the array reference, the data is stored consecutively in memory, so we can maximize the amount of computation per data fetch. An array of object references will get good locality when fetching the next reference in the array, but risks a cache miss when dereferencing those object references. Similarly, a class containing multiple primitive fields will likely lay the fields out near one another in memory, whereas a class containing many object references will require many dereferences to access its state. Ultimately, the more pointer-rich a data structure is, the more pressure traversing such a data structure places on the memory fetch units, which can have a negative effect both on computation time (while the CPUs spend time waiting for data) and parallelism (as many cores fetching simultaneously from memory put pressure on the bandwidth available to transfer data from memory to cache).</p>
<h2 id="thenqmodel" class="ibm-h2">The <em>NQ</em> model</h2>
<p class="cye-lm-tag">To determine whether parallelism will offer a speedup, the final factors to consider are the amount of data available and the amount of computation performed per data element.</p>
<p class="cye-lm-tag">In our initial description of parallel decomposition, we appealed to the notion of splitting the source until the segments are so small that a sequential approach for solving the problem on that segment would be more efficient. How small the segments must be depends on the problem being solved, and specifically, how much work is done per element. For example, computing the length of a string involves far less work than computing the string's SHA-1 hash. The more work done per element, the lower the threshold for "large enough to extract parallelism." Similarly, the more data we have, the more segments into which we can divide it without running afoul of the "too small" threshold.</p>
<p class="cye-lm-tag">A simple but useful model for parallel performance is the <em>NQ</em> model, where <em>N</em> is the number of data elements, and <em>Q</em> is the amount of work performed per element. The larger the product     <em>N*Q</em>, the more likely we are to get a parallel speedup. For problems with trivially small <em>Q</em>, such as adding up numbers, you generally want to see <em>N</em> &gt; 10,000 to get a speedup; as     <em>Q</em> increases, the data size required to get a speedup decreases.</p>
<p class="cye-lm-tag">Many of the impediments to parallelism — such as splitting cost, combining cost, or encounter order sensitivity — are moderated by higher <em>Q</em> operations. While the splitting characteristics of a <code>LinkedList</code> might be awful, it's still possible to get a parallel speedup given a large enough <em>Q</em>.</p>
<h2 id="N10243" class="ibm-h2">Conclusion</h2>
<p class="cye-lm-tag">Because parallelism offers only the potential for faster runtime, you should use it only when it produces an actual speedup. Develop and test your code using sequential streams; then, if your performance requirements suggest that further improvement is needed, consider parallelism as a possible optimization strategy. Although measurement is critical to ensuring that your optimization efforts aren't counterproductive, for many stream pipelines, you can determine via inspection that they aren't good candidates for parallelization. Factors that chip away at potential parallel speedup include poorly or unevenly splitting sources, high combination costs, dependence on encounter order, poor locality, or not enough data. On the other hand, a large amount of computation (<em>Q</em>) per element can make up for some of these deficiencies.</p>
<!--CMA ID: 1034729--><!--Site ID: 1--><!--XSLT stylesheet used to transform this file: dw-document-html-8.0.xsl-->                   <!-- CENTER_6_4_CONTENT_COLUMN_END -->     </div> <br><hr> <a href="http://stackoverflow.com/questions/24676877/should-i-return-a-collection-or-a-stream/24679745#24679745">Should I return a Collection or a Stream?</a> <div class="post-text cye-lm-tag" itemprop="text"> <p class="cye-lm-tag">The answer is, as always, "it depends".  It depends on how big the returned collection will be.  It depends on whether the result changes over time, and how important consistency of the returned result is.  And it depends very much on how the user is likely to use the answer.  </p>
  <p class="cye-lm-tag">First, note that you can always get a Collection from a Stream, and vice versa:</p>
  <pre class="lang-java prettyprint prettyprinted"><code><span class="com cye-lm-tag">// If API returns Collection, convert with stream()</span><span class="pln cye-lm-tag"> getFoo</span><span class="pun cye-lm-tag">().</span><span class="pln cye-lm-tag">stream</span><span class="pun cye-lm-tag">()...</span><span class="pln cye-lm-tag">  </span><span class="com cye-lm-tag">// If API returns Stream, use collect()</span><span class="pln cye-lm-tag"> </span><span class="typ cye-lm-tag">Collection</span><span class="pun cye-lm-tag">&lt;</span><span class="pln cye-lm-tag">T</span><span class="pun cye-lm-tag">&gt;</span><span class="pln cye-lm-tag"> c </span><span class="pun cye-lm-tag">=</span><span class="pln cye-lm-tag"> getFooStream</span><span class="pun cye-lm-tag">().</span><span class="pln cye-lm-tag">collect</span><span class="pun cye-lm-tag">(</span><span class="pln cye-lm-tag">toList</span><span class="pun cye-lm-tag">());</span></code></pre>  <p class="cye-lm-tag">So the question is, which is more useful to your callers.  </p>
  <p class="cye-lm-tag">If your result might be infinite, there's only one choice: Stream.</p>
  <p class="cye-lm-tag">If your result might be very large, you probably prefer Stream, since there may not be any value in materializing it all at once, and doing so could create significant heap pressure.</p>
  <p class="cye-lm-tag">If all the caller is going to do is iterate through it (search, filter, aggregate), you should prefer Stream, since Stream has these built-in already and there's no need to materialize a collection (especially if the user might not process the whole result.)  This is a very common case.  </p>
  <p class="cye-lm-tag">Even if you know that the user will iterate it multiple times or otherwise keep it around, you still may want to return a Stream instead, for the simple fact that whatever Collection you choose to put it in (e.g., ArrayList) may not be the form they want, and then the caller has to copy it anyway.  if you return a stream, they can do <code>collect(toCollection(factory))</code> and get it in exactly the form they want.</p>
  <p class="cye-lm-tag">The above "prefer Stream" cases mostly derive from the fact that Stream is more flexible; you can late-bind to how you use it without incurring the costs and constraints of materializing it to a Collection.  </p>
  <p class="cye-lm-tag">The one case where you must return a Collection is when there are strong consistency requirements, and you have to produce a consistent snapshot of a moving target.  Then, you will want put the elements into a collection that will not change.</p>
  <p class="cye-lm-tag">So I would say that most of the time, Stream is the right answer -- it is more flexible, it doesn't impose usually-unnecessary materialization costs, and can be easily turned into the Collection of your choice if needed.  But sometimes, you may have to return a Collection (say, due to strong consistency requirements), or you may want to return Collection because you know how the user will be using it and know this is the most convenient thing for them.  </p>
     </div>      </body> </html>